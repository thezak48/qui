This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.claude/
  settings.local.json
.github/
  workflows/
    test.yaml
  dependabot.yml
errors/
  errors_test.go
  errors.go
examples/
  basic/
    main.go
.gitignore
domain_test.go
domain.go
go.mod
http.go
LICENSE
maindata.go
methods_test.go
methods.go
qbittorrent.go
README.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".claude/settings.local.json">
{
  "permissions": {
    "allow": [
      "Bash(grep:*)"
    ],
    "deny": []
  }
}
</file>

<file path=".github/dependabot.yml">
version: 2
updates:
  - package-ecosystem: github-actions
    directory: /
    schedule:
      interval: weekly
      day: saturday
      time: "07:00"
    groups:
      github:
        patterns:
          - "*"

  - package-ecosystem: gomod
    directory: /
    schedule:
      interval: monthly
    groups:
      golang:
        patterns:
          - "*"
</file>

<file path="errors/errors_test.go">
package errors_test

//import (
//	"fmt"
//
//	"github.com/incident-io/core/server/pkg/errors"
//
//	. "github.com/onsi/ginkgo"
//	. "github.com/onsi/gomega"
//)
//
//func getStackTraces(err error) []errors.StackTrace {
//	traces := []errors.StackTrace{}
//	if err, ok := err.(errors.StackTracer); ok {
//		traces = append(traces, err.StackTrace())
//	}
//
//	if err := errors.Unwrap(err); err != nil {
//		traces = append(traces, getStackTraces(err)...)
//	}
//
//	return traces
//}
//
//var _ = Describe("errors", func() {
//	Describe("New", func() {
//		It("generates an error with a stack trace", func() {
//			err := errors.New("oops")
//			Expect(getStackTraces(err)).To(HaveLen(1))
//		})
//	})
//
//	Describe("Wrap", func() {
//		Context("when cause has no stack trace", func() {
//			It("wraps the error and takes stack trace", func() {
//				err := errors.Wrap(fmt.Errorf("cause"), "description")
//				Expect(err.Error()).To(Equal("description: cause"))
//
//				cause := errors.Cause(err)
//				Expect(cause).To(MatchError("cause"))
//
//				Expect(getStackTraces(err)).To(HaveLen(1))
//			})
//		})
//
//		Context("when cause has stack trace", func() {
//			Context("which is not an ancestor of our own", func() {
//				It("creates a new stack trace", func() {
//					errChan := make(chan error)
//					go func() {
//						errChan <- errors.New("unrelated") // created with a stack trace
//					}()
//
//					err := errors.Wrap(<-errChan, "helpful description")
//					Expect(err.Error()).To(Equal("helpful description: unrelated"))
//
//					Expect(getStackTraces(err)).To(HaveLen(2))
//				})
//			})
//
//			Context("with a frame from our current method", func() {
//				It("does not create new stack trace", func() {
//					err := errors.Wrap(errors.New("related"), "helpful description")
//					Expect(err.Error()).To(Equal("helpful description: related"))
//
//					Expect(getStackTraces(err)).To(HaveLen(1))
//				})
//			})
//		})
//	})
//})
</file>

<file path="errors/errors.go">
package errors

import (
	"fmt"
	"reflect"
	"runtime"
	"unsafe"

	"github.com/pkg/errors"
)

// Export a number of functions or variables from pkg/errors. We want people to be able to
// use them, if only via the entrypoints we've vetted in this file.
var (
	As     = errors.As
	Is     = errors.Is
	Cause  = errors.Cause
	Unwrap = errors.Unwrap
)

// StackTrace should be aliases rather than newtype'd, so it can work with any of the
// functions we export from pkg/errors.
type StackTrace = errors.StackTrace

type StackTracer interface {
	StackTrace() errors.StackTrace
}

// Sentinel is used to create compile-time errors that are intended to be value only, with
// no associated stack trace.
func Sentinel(msg string, args ...interface{}) error {
	return fmt.Errorf(msg, args...)
}

// New acts as pkg/errors.New does, producing a stack traced error, but supports
// interpolating of message parameters. Use this when you want the stack trace to start at
// the place you create the error.
func New(msg string, args ...interface{}) error {
	return PopStack(errors.New(fmt.Sprintf(msg, args...)))
}

// Wrap creates a new error from a cause, decorating the original error message with a
// prefix.
//
// It differs from the pkg/errors Wrap/Wrapf by idempotently creating a stack trace,
// meaning we won't create another stack trace when there is already a stack trace present
// that matches our current program position.
func Wrap(cause error, msg string, args ...interface{}) error {
	causeStackTracer := new(StackTracer)
	if errors.As(cause, causeStackTracer) {
		// If our cause has set a stack trace, and that trace is a child of our own function
		// as inferred by prefix matching our current program counter stack, then we only want
		// to decorate the error message rather than add a redundant stack trace.
		if ancestorOfCause(callers(1), (*causeStackTracer).StackTrace()) {
			return errors.WithMessagef(cause, msg, args...) // no stack added, no pop required
		}
	}

	// Otherwise we can't see a stack trace that represents ourselves, so let's add one.
	return PopStack(errors.Wrapf(cause, msg, args...))
}

// ancestorOfCause returns true if the caller looks to be an ancestor of the given stack
// trace. We check this by seeing whether our stack prefix-matches the cause stack, which
// should imply the error was generated directly from our goroutine.
func ancestorOfCause(ourStack []uintptr, causeStack errors.StackTrace) bool {
	// Stack traces are ordered such that the deepest frame is first. We'll want to check
	// for prefix matching in reverse.
	//
	// As an example, imagine we have a prefix-matching stack for ourselves:
	// [
	//   "github.com/onsi/ginkgo/internal/leafnodes.(*runner).runSync",
	//   "github.com/incident-io/core/server/pkg/errors_test.TestSuite",
	//   "testing.tRunner",
	//   "runtime.goexit"
	// ]
	//
	// We'll want to compare this against an error cause that will have happened further
	// down the stack. An example stack trace from such an error might be:
	// [
	//   "github.com/incident-io/core/server/pkg/errors.New",
	//   "github.com/incident-io/core/server/pkg/errors_test.glob..func1.2.2.2.1",,
	//   "github.com/onsi/ginkgo/internal/leafnodes.(*runner).runSync",
	//   "github.com/incident-io/core/server/pkg/errors_test.TestSuite",
	//   "testing.tRunner",
	//   "runtime.goexit"
	// ]
	//
	// They prefix match, but we'll have to handle the match carefully as we need to match
	// from back to forward.

	// We can't possibly prefix match if our stack is larger than the cause stack.
	if len(ourStack) > len(causeStack) {
		return false
	}

	// We know the sizes are compatible, so compare program counters from back to front.
	for idx := 0; idx < len(ourStack); idx++ {
		if ourStack[len(ourStack)-1] != (uintptr)(causeStack[len(causeStack)-1]) {
			return false
		}
	}

	// All comparisons checked out, these stacks match
	return true
}

func callers(skip int) []uintptr {
	pc := make([]uintptr, 32)        // assume we'll have at most 32 frames
	n := runtime.Callers(skip+3, pc) // capture those frames, skipping runtime.Callers, ourself and the calling function

	return pc[:n] // return everything that we captured
}

// RecoverPanic turns a panic into an error, adjusting the stacktrace so it originates at
// the line that caused it.
//
// Example:
//
// func Do() (err error) {
//   defer func() {
//     errors.RecoverPanic(recover(), &err)
//   }()
// }
func RecoverPanic(r interface{}, errPtr *error) {
	var err error
	if r != nil {
		if panicErr, ok := r.(error); ok {
			err = errors.Wrap(panicErr, "caught panic")
		} else {
			err = errors.New(fmt.Sprintf("caught panic: %v", r))
		}
	}

	if err != nil {
		// Pop twice: once for the errors package, then again for the defer function we must
		// run this under. We want the stacktrace to originate at the source of the panic, not
		// in the infrastructure that catches it.
		err = PopStack(err) // errors.go
		err = PopStack(err) // defer

		*errPtr = err
	}
}

// PopStack removes the top of the stack from an errors stack trace.
func PopStack(err error) error {
	if err == nil {
		return err
	}

	// We want to remove us, the internal/errors.New function, from the error stack we just
	// produced. There's no official way of reaching into the error and adjusting this, as
	// the stack is stored as a private field on an unexported struct.
	//
	// This does some unsafe badness to adjust that field, which should not be repeated
	// anywhere else.
	stackField := reflect.ValueOf(err).Elem().FieldByName("stack")
	if stackField.IsZero() {
		return err
	}
	stackFieldPtr := (**[]uintptr)(unsafe.Pointer(stackField.UnsafeAddr()))

	// Remove the first of the frames, dropping 'us' from the error stack trace.
	frames := (**stackFieldPtr)[1:]

	// Assign to the internal stack field
	*stackFieldPtr = &frames

	return err
}
</file>

<file path="examples/basic/main.go">
package main

import (
	"context"
	"log"

	"github.com/autobrr/go-qbittorrent"
)

func main() {
	client := qbittorrent.NewClient(qbittorrent.Config{
		Host:     "http://localhost:8080",
		Username: "admin",
		Password: "adminadmin",
	})

	ctx := context.Background()

	if err := client.LoginCtx(ctx); err != nil {
		log.Fatalf("could not log into client: %q", err)
	}

	torrents, err := client.GetTorrents(qbittorrent.TorrentFilterOptions{
		Category: "test",
	})
	if err != nil {
		log.Fatalf("could not get torrents from client: %q", err)
	}

	log.Printf("Found %d torrents", len(torrents))
}
</file>

<file path=".gitignore">
# Logs and databases #
######################
*.log

# OS generated files #
######################
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Other
.idea
eb/build
bin/
log/
dist/
</file>

<file path="LICENSE">
MIT License

Copyright (c) 2022 autobrr

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</file>

<file path="maindata.go">
package qbittorrent

import (
	"context"

	"golang.org/x/exp/slices"
)

func (dest *MainData) Update(ctx context.Context, c *Client) error {
	source, err := c.SyncMainDataCtx(ctx, int64(dest.Rid))
	if err != nil {
		return err
	}

	if source.FullUpdate {
		*dest = *source
		return nil
	}

	dest.Rid = source.Rid
	dest.ServerState = source.ServerState
	merge(source.Categories, &dest.Categories)
	merge(source.Torrents, &dest.Torrents)
	merge(source.Trackers, &dest.Trackers)
	remove(source.CategoriesRemoved, &dest.Categories)
	remove(source.TorrentsRemoved, &dest.Torrents)
	mergeSlice(source.Tags, &dest.Tags)
	removeSlice(source.TagsRemoved, &dest.Tags)
	return nil
}

func merge[T map[string]V, V any](s T, d *T) {
	for k, v := range s {
		(*d)[k] = v
	}
}

func remove[T map[string]V, V any](s []string, d *T) {
	for _, v := range s {
		delete(*d, v)
	}
}

func mergeSlice[T []string](s T, d *T) {
	*d = append(*d, s...)
	slices.Sort(*d)
	*d = slices.Compact(*d)
}

func removeSlice[T []string](s T, d *T) {
	for i := 0; i < len(*d); i++ {
		if k := (*d)[i]; len(k) != 0 {
			match := false
			for _, c := range s {
				if c == k {
					match = true
					break
				}
			}

			if !match {
				continue
			}
		}

		(*d)[i] = (*d)[len(*d)-1]
		(*d) = (*d)[:len(*d)-1]
		i--
	}
}
</file>

<file path="README.md">
# go-qbittorrent

Go library for communicating with qBittorrent.
</file>

<file path=".github/workflows/test.yaml">
name: test

on:
  push:
    branches:
      - "master"
      - "develop"
    tags:
      - 'v*'
  pull_request:

jobs:
  test:
    name: Test
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.21.0'
          cache: true

      - name: Test
        run: go test -tags ci -v ./...
</file>

<file path="methods_test.go">
//go:build !ci
// +build !ci

package qbittorrent_test

import (
	"os"
	"testing"
	"time"

	"github.com/stretchr/testify/assert"

	"github.com/autobrr/go-qbittorrent"
)

const (
	// a sample torrent that only contains one folder "untitled" and one file "untitled.txt".
	sampleTorrent  = "d10:created by18:qBittorrent v5.1.013:creation datei1747004328e4:infod5:filesld6:lengthi21e4:pathl12:untitled.txteee4:name8:untitled12:piece lengthi16384e6:pieces20:\xb5|\x901\xce\xa3\xdb @$\xce\xbd\xd3\xb0\x0e\xd3\xba\xc0\xcc\xbd7:privatei1eee"
	sampleInfoHash = "ead9241e611e9712f28b20b151f1a3ecd4a6178a"
)

var (
	qBittorrentBaseURL  string
	qBittorrentUsername string
	qBittorrentPassword string
)

func init() {
	qBittorrentBaseURL = "http://127.0.0.1:8080/"
	if val := os.Getenv("QBIT_BASE_URL"); val != "" {
		qBittorrentBaseURL = val
	}
	qBittorrentUsername = "admin"
	if val := os.Getenv("QBIT_USERNAME"); val != "" {
		qBittorrentUsername = val
	}
	qBittorrentPassword = "password" // must be at least 6 characters
	if val := os.Getenv("QBIT_PASSWORD"); val != "" {
		qBittorrentPassword = val
	}
}

func TestClient_GetDefaultSavePath(t *testing.T) {
	client := qbittorrent.NewClient(qbittorrent.Config{
		Host:     qBittorrentBaseURL,
		Username: qBittorrentUsername,
		Password: qBittorrentPassword,
	})

	_, err := client.GetDefaultSavePath()
	assert.NoError(t, err)
}

func TestClient_GetAppCookies(t *testing.T) {
	client := qbittorrent.NewClient(qbittorrent.Config{
		Host:     qBittorrentBaseURL,
		Username: qBittorrentUsername,
		Password: qBittorrentPassword,
	})

	_, err := client.GetAppCookies()
	assert.NoError(t, err)
}

func TestClient_SetAppCookies(t *testing.T) {
	client := qbittorrent.NewClient(qbittorrent.Config{
		Host:     qBittorrentBaseURL,
		Username: qBittorrentUsername,
		Password: qBittorrentPassword,
	})

	var err error
	var cookies = []qbittorrent.Cookie{
		{
			Name:           "test",
			Domain:         "example.com",
			Path:           "/",
			Value:          "test",
			ExpirationDate: time.Now().Add(time.Hour).Unix(),
		},
	}
	err = client.SetAppCookies(cookies)
	assert.NoError(t, err)

	resp, err := client.GetAppCookies()
	assert.NoError(t, err)
	assert.NotEmpty(t, cookies)
	assert.Equal(t, cookies, resp)
}

func TestClient_BanPeers(t *testing.T) {
	client := qbittorrent.NewClient(qbittorrent.Config{
		Host:     qBittorrentBaseURL,
		Username: qBittorrentUsername,
		Password: qBittorrentPassword,
	})

	err := client.BanPeers([]string{"127.0.0.1:80"})
	assert.NoError(t, err)
}

func TestClient_GetBuildInfo(t *testing.T) {
	client := qbittorrent.NewClient(qbittorrent.Config{
		Host:     qBittorrentBaseURL,
		Username: qBittorrentUsername,
		Password: qBittorrentPassword,
	})

	bi, err := client.GetBuildInfo()
	assert.NoError(t, err)
	assert.NotEmpty(t, bi.Qt)
	assert.NotEmpty(t, bi.Libtorrent)
	assert.NotEmpty(t, bi.Boost)
	assert.NotEmpty(t, bi.Openssl)
	assert.NotEmpty(t, bi.Bitness)
}

func TestClient_GetTorrentDownloadLimit(t *testing.T) {
	client := qbittorrent.NewClient(qbittorrent.Config{
		Host:     qBittorrentBaseURL,
		Username: qBittorrentUsername,
		Password: qBittorrentPassword,
	})

	data, err := client.GetTorrents(qbittorrent.TorrentFilterOptions{})
	assert.NoError(t, err)
	var hashes []string
	for _, torrent := range data {
		hashes = append(hashes, torrent.Hash)
	}

	limits, err := client.GetTorrentDownloadLimit(hashes)
	assert.NoError(t, err)
	assert.Equal(t, len(hashes), len(limits))

	// FIXME: The following assertion will fail.
	// Neither "hashes=all" nor "all" is working.
	// I have no idea. Maybe the document is lying?
	//
	// limits, err = client.GetTorrentDownloadLimit([]string{"all"})
	// assert.NoError(t, err)
	// assert.Equal(t, len(hashes), len(limits))
}

func TestClient_GetTorrentUploadLimit(t *testing.T) {
	client := qbittorrent.NewClient(qbittorrent.Config{
		Host:     qBittorrentBaseURL,
		Username: qBittorrentUsername,
		Password: qBittorrentPassword,
	})

	data, err := client.GetTorrents(qbittorrent.TorrentFilterOptions{})
	assert.NoError(t, err)
	var hashes []string
	for _, torrent := range data {
		hashes = append(hashes, torrent.Hash)
	}

	limits, err := client.GetTorrentUploadLimit(hashes)
	assert.NoError(t, err)
	assert.Equal(t, len(hashes), len(limits))

	// FIXME: The following assertion will fail.
	// Neither "hashes=all" nor "all" is working.
	// I have no idea. Maybe the document is lying?
	// Just as same as Client.GetTorrentDownloadLimit.
	//
	// limits, err = client.GetTorrentDownloadLimit([]string{"all"})
	// assert.NoError(t, err)
	// assert.Equal(t, len(hashes), len(limits))
}

func TestClient_ToggleTorrentSequentialDownload(t *testing.T) {
	client := qbittorrent.NewClient(qbittorrent.Config{
		Host:     qBittorrentBaseURL,
		Username: qBittorrentUsername,
		Password: qBittorrentPassword,
	})

	var err error

	data, err := client.GetTorrents(qbittorrent.TorrentFilterOptions{})
	assert.NoError(t, err)
	var hashes []string
	for _, torrent := range data {
		hashes = append(hashes, torrent.Hash)
	}

	err = client.ToggleTorrentSequentialDownload(hashes)
	assert.NoError(t, err)

	// No idea why this is working but downloadLimit/uploadLimit are not.
	err = client.ToggleTorrentSequentialDownload([]string{"all"})
	assert.NoError(t, err)
}

func TestClient_SetTorrentSuperSeeding(t *testing.T) {
	client := qbittorrent.NewClient(qbittorrent.Config{
		Host:     qBittorrentBaseURL,
		Username: qBittorrentUsername,
		Password: qBittorrentPassword,
	})

	var err error

	data, err := client.GetTorrents(qbittorrent.TorrentFilterOptions{})
	assert.NoError(t, err)
	var hashes []string
	for _, torrent := range data {
		hashes = append(hashes, torrent.Hash)
	}

	err = client.SetTorrentSuperSeeding(hashes, true)
	assert.NoError(t, err)

	// FIXME: following test not fail but has no effect.
	// qBittorrent doesn't return any error but super seeding status is not changed.
	// I tried specify hashes as "all" but it's not working too.
	err = client.SetTorrentSuperSeeding([]string{"all"}, false)
	assert.NoError(t, err)
}

func TestClient_GetTorrentPieceStates(t *testing.T) {
	client := qbittorrent.NewClient(qbittorrent.Config{
		Host:     qBittorrentBaseURL,
		Username: qBittorrentUsername,
		Password: qBittorrentPassword,
	})

	data, err := client.GetTorrents(qbittorrent.TorrentFilterOptions{})
	assert.NoError(t, err)
	assert.NotEmpty(t, data)

	hash := data[0].Hash
	states, err := client.GetTorrentPieceStates(hash)
	assert.NoError(t, err)
	assert.NotEmpty(t, states)
}

func TestClient_GetTorrentPieceHashes(t *testing.T) {
	client := qbittorrent.NewClient(qbittorrent.Config{
		Host:     qBittorrentBaseURL,
		Username: qBittorrentUsername,
		Password: qBittorrentPassword,
	})

	data, err := client.GetTorrents(qbittorrent.TorrentFilterOptions{})
	assert.NoError(t, err)
	assert.NotEmpty(t, data)

	hash := data[0].Hash
	states, err := client.GetTorrentPieceHashes(hash)
	assert.NoError(t, err)
	assert.NotEmpty(t, states)
}

func TestClient_AddPeersForTorrents(t *testing.T) {
	client := qbittorrent.NewClient(qbittorrent.Config{
		Host:     qBittorrentBaseURL,
		Username: qBittorrentUsername,
		Password: qBittorrentPassword,
	})

	data, err := client.GetTorrents(qbittorrent.TorrentFilterOptions{})
	assert.NoError(t, err)
	assert.NotEmpty(t, data)

	hashes := []string{data[0].Hash}
	peers := []string{"127.0.0.1:12345"}
	err = client.AddPeersForTorrents(hashes, peers)
	// It seems qBittorrent doesn't actually check whether given peers are available.
	assert.NoError(t, err)
}

func TestClient_RenameFile(t *testing.T) {
	client := qbittorrent.NewClient(qbittorrent.Config{
		Host:     qBittorrentBaseURL,
		Username: qBittorrentUsername,
		Password: qBittorrentPassword,
	})

	err := client.AddTorrentFromMemory([]byte(sampleTorrent), nil)
	assert.NoError(t, err)
	defer func(client *qbittorrent.Client) {
		_ = client.DeleteTorrents([]string{sampleInfoHash}, false)
	}(client)

	err = client.RenameFile(sampleInfoHash, "untitled/untitled.txt", "untitled/renamed.txt")
	assert.NoError(t, err)
}

func TestClient_RenameFolder(t *testing.T) {
	client := qbittorrent.NewClient(qbittorrent.Config{
		Host:     qBittorrentBaseURL,
		Username: qBittorrentUsername,
		Password: qBittorrentPassword,
	})

	err := client.AddTorrentFromMemory([]byte(sampleTorrent), nil)
	assert.NoError(t, err)
	defer func(client *qbittorrent.Client) {
		_ = client.DeleteTorrents([]string{sampleInfoHash}, false)
	}(client)

	err = client.RenameFolder(sampleInfoHash, "untitled", "renamed")
	assert.NoError(t, err)
}

func TestClient_GetTorrentsWebSeeds(t *testing.T) {
	client := qbittorrent.NewClient(qbittorrent.Config{
		Host:     qBittorrentBaseURL,
		Username: qBittorrentUsername,
		Password: qBittorrentPassword,
	})

	data, err := client.GetTorrents(qbittorrent.TorrentFilterOptions{})
	assert.NoError(t, err)
	assert.NotEmpty(t, data)

	hash := data[0].Hash
	_, err = client.GetTorrentsWebSeeds(hash)
	assert.NoError(t, err)
}
</file>

<file path="domain_test.go">
package qbittorrent

import (
	"testing"

	"github.com/stretchr/testify/assert"
)

func TestTorrentAddOptions_Prepare(t *testing.T) {
	type fields struct {
		Paused             bool
		SkipHashCheck      bool
		ContentLayout      ContentLayout
		SavePath           string
		AutoTMM            bool
		Category           string
		Tags               string
		LimitUploadSpeed   int64
		LimitDownloadSpeed int64
		LimitRatio         float64
		LimitSeedTime      int64
		Rename             string
		FirstLastPiecePrio bool
	}
	tests := []struct {
		name   string
		fields fields
		want   map[string]string
	}{
		{
			name: "test_01",
			fields: fields{
				Paused:             false,
				SkipHashCheck:      true,
				ContentLayout:      "",
				SavePath:           "/home/test/torrents",
				AutoTMM:            false,
				Category:           "test",
				Tags:               "limited,slow",
				LimitUploadSpeed:   100000,
				LimitDownloadSpeed: 100000,
				LimitRatio:         2.0,
				LimitSeedTime:      100,
			},
			want: map[string]string{
				"paused":             "false",
				"stopped":            "false",
				"skip_checking":      "true",
				"autoTMM":            "false",
				"firstLastPiecePrio": "false",
				"ratioLimit":         "2.00",
				"savepath":           "/home/test/torrents",
				"seedingTimeLimit":   "100",
				"category":           "test",
				"tags":               "limited,slow",
				"upLimit":            "102400000",
				"dlLimit":            "102400000",
			},
		},
		{
			name: "test_02",
			fields: fields{
				Paused:             false,
				SkipHashCheck:      true,
				ContentLayout:      ContentLayoutSubfolderCreate,
				SavePath:           "/home/test/torrents",
				AutoTMM:            false,
				Category:           "test",
				Tags:               "limited,slow",
				LimitUploadSpeed:   100000,
				LimitDownloadSpeed: 100000,
				LimitRatio:         2.0,
				LimitSeedTime:      100,
			},
			want: map[string]string{
				"paused":             "false",
				"stopped":            "false",
				"skip_checking":      "true",
				"root_folder":        "true",
				"contentLayout":      "Subfolder",
				"autoTMM":            "false",
				"firstLastPiecePrio": "false",
				"ratioLimit":         "2.00",
				"savepath":           "/home/test/torrents",
				"seedingTimeLimit":   "100",
				"category":           "test",
				"tags":               "limited,slow",
				"upLimit":            "102400000",
				"dlLimit":            "102400000",
			},
		},
		{
			name: "test_03",
			fields: fields{
				Paused:             false,
				SkipHashCheck:      true,
				ContentLayout:      ContentLayoutSubfolderNone,
				SavePath:           "/home/test/torrents",
				AutoTMM:            false,
				Category:           "test",
				Tags:               "limited,slow",
				LimitUploadSpeed:   100000,
				LimitDownloadSpeed: 100000,
				LimitRatio:         2.0,
				LimitSeedTime:      100,
			},
			want: map[string]string{
				"paused":             "false",
				"stopped":            "false",
				"skip_checking":      "true",
				"root_folder":        "false",
				"contentLayout":      "NoSubfolder",
				"autoTMM":            "false",
				"firstLastPiecePrio": "false",
				"ratioLimit":         "2.00",
				"savepath":           "/home/test/torrents",
				"seedingTimeLimit":   "100",
				"category":           "test",
				"tags":               "limited,slow",
				"upLimit":            "102400000",
				"dlLimit":            "102400000",
			},
		},
		{
			name: "test_04",
			fields: fields{
				Paused:             false,
				SkipHashCheck:      true,
				ContentLayout:      ContentLayoutOriginal,
				SavePath:           "/home/test/torrents",
				AutoTMM:            false,
				Category:           "test",
				Tags:               "limited,slow",
				LimitUploadSpeed:   100000,
				LimitDownloadSpeed: 100000,
				LimitRatio:         2.0,
				LimitSeedTime:      100,
			},
			want: map[string]string{
				"paused":             "false",
				"stopped":            "false",
				"skip_checking":      "true",
				"autoTMM":            "false",
				"firstLastPiecePrio": "false",
				"ratioLimit":         "2.00",
				"savepath":           "/home/test/torrents",
				"seedingTimeLimit":   "100",
				"category":           "test",
				"tags":               "limited,slow",
				"upLimit":            "102400000",
				"dlLimit":            "102400000",
			},
		},
		{
			name: "test_05",
			fields: fields{
				Paused:             false,
				SkipHashCheck:      true,
				ContentLayout:      ContentLayoutOriginal,
				SavePath:           "/home/test/torrents",
				AutoTMM:            false,
				Category:           "test",
				Tags:               "limited,slow",
				LimitUploadSpeed:   100000,
				LimitDownloadSpeed: 100000,
				LimitRatio:         2.0,
				LimitSeedTime:      100,
				Rename:             "test-torrent-rename",
			},
			want: map[string]string{
				"paused":             "false",
				"stopped":            "false",
				"skip_checking":      "true",
				"autoTMM":            "false",
				"firstLastPiecePrio": "false",
				"ratioLimit":         "2.00",
				"savepath":           "/home/test/torrents",
				"seedingTimeLimit":   "100",
				"category":           "test",
				"tags":               "limited,slow",
				"upLimit":            "102400000",
				"dlLimit":            "102400000",
				"rename":             "test-torrent-rename",
			},
		},
		{
			name: "test_06",
			fields: fields{
				Paused:             false,
				SkipHashCheck:      true,
				ContentLayout:      ContentLayoutOriginal,
				SavePath:           "/home/test/torrents",
				AutoTMM:            false,
				FirstLastPiecePrio: true,
				Category:           "test",
				Tags:               "limited,slow",
				LimitUploadSpeed:   100000,
				LimitDownloadSpeed: 100000,
				LimitRatio:         2.0,
				LimitSeedTime:      100,
				Rename:             "test-torrent-rename",
			},
			want: map[string]string{
				"paused":             "false",
				"stopped":            "false",
				"skip_checking":      "true",
				"autoTMM":            "false",
				"firstLastPiecePrio": "true",
				"ratioLimit":         "2.00",
				"savepath":           "/home/test/torrents",
				"seedingTimeLimit":   "100",
				"category":           "test",
				"tags":               "limited,slow",
				"upLimit":            "102400000",
				"dlLimit":            "102400000",
				"rename":             "test-torrent-rename",
			},
		},
	}
	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			o := &TorrentAddOptions{
				Paused:             tt.fields.Paused,
				SkipHashCheck:      tt.fields.SkipHashCheck,
				ContentLayout:      tt.fields.ContentLayout,
				SavePath:           tt.fields.SavePath,
				AutoTMM:            tt.fields.AutoTMM,
				Category:           tt.fields.Category,
				Tags:               tt.fields.Tags,
				LimitUploadSpeed:   tt.fields.LimitUploadSpeed,
				LimitDownloadSpeed: tt.fields.LimitDownloadSpeed,
				LimitRatio:         tt.fields.LimitRatio,
				LimitSeedTime:      tt.fields.LimitSeedTime,
				Rename:             tt.fields.Rename,
				FirstLastPiecePrio: tt.fields.FirstLastPiecePrio,
			}

			got := o.Prepare()
			assert.Equal(t, tt.want, got)
		})
	}
}
</file>

<file path="qbittorrent.go">
package qbittorrent

import (
	"crypto/tls"
	"io"
	"log"
	"net"
	"net/http"
	"net/http/cookiejar"
	"time"

	"github.com/Masterminds/semver"
	"golang.org/x/net/publicsuffix"
)

var (
	DefaultTimeout = 60 * time.Second
)

type Client struct {
	cfg Config

	http    *http.Client
	timeout time.Duration

	log *log.Logger

	version *semver.Version
}

type Config struct {
	Host     string
	Username string
	Password string

	// TLS skip cert validation
	TLSSkipVerify bool

	// HTTP Basic auth username
	BasicUser string

	// HTTP Basic auth password
	BasicPass string

	Timeout int
	Log     *log.Logger
}

func NewClient(cfg Config) *Client {
	c := &Client{
		cfg:     cfg,
		log:     log.New(io.Discard, "", log.LstdFlags),
		timeout: DefaultTimeout,
	}

	// override logger if we pass one
	if cfg.Log != nil {
		c.log = cfg.Log
	}

	if cfg.Timeout > 0 {
		c.timeout = time.Duration(cfg.Timeout) * time.Second
	}

	//store cookies in jar
	jarOptions := &cookiejar.Options{PublicSuffixList: publicsuffix.List}
	jar, err := cookiejar.New(jarOptions)
	if err != nil {
		c.log.Println("new client cookie error")
	}

	customTransport := &http.Transport{
		Proxy: http.ProxyFromEnvironment,
		DialContext: (&net.Dialer{
			Timeout:   30 * time.Second, // default transport value
			KeepAlive: 30 * time.Second, // default transport value
		}).DialContext,
		ForceAttemptHTTP2:     true,             // default is true; since HTTP/2 multiplexes a single TCP connection. we'd want to use HTTP/1, which would use multiple TCP connections.
		MaxIdleConns:          100,              // default transport value
		MaxIdleConnsPerHost:   10,               // default is 2, so we want to increase the number to use establish more connections.
		IdleConnTimeout:       90 * time.Second, // default transport value
		TLSHandshakeTimeout:   10 * time.Second, // default transport value
		ExpectContinueTimeout: 1 * time.Second,  // default transport value
		ReadBufferSize:        65536,
		WriteBufferSize:       65536,
		TLSClientConfig: &tls.Config{
			InsecureSkipVerify: cfg.TLSSkipVerify,
		},
	}

	c.http = &http.Client{
		Jar:       jar,
		Timeout:   c.timeout,
		Transport: customTransport,
	}

	return c
}

// WithHTTPClient allows you to a provide a custom [http.Client].
func (c *Client) WithHTTPClient(client *http.Client) *Client {
	client.Jar = c.http.Jar
	c.http = client
	return c
}
</file>

<file path="http.go">
package qbittorrent

import (
	"bytes"
	"context"
	"io"
	"math/rand"
	"mime/multipart"
	"net/http"
	"net/url"
	"os"
	"strings"
	"time"

	"github.com/autobrr/go-qbittorrent/errors"
	"github.com/avast/retry-go"
)

func (c *Client) getCtx(ctx context.Context, endpoint string, opts map[string]string) (*http.Response, error) {
	reqUrl := c.buildUrl(endpoint, opts)

	req, err := http.NewRequestWithContext(ctx, http.MethodGet, reqUrl, nil)
	if err != nil {
		return nil, errors.Wrap(err, "could not build request")
	}

	if c.cfg.BasicUser != "" && c.cfg.BasicPass != "" {
		req.SetBasicAuth(c.cfg.BasicUser, c.cfg.BasicPass)
	}

	cookieURL, _ := url.Parse(c.buildUrl("/", nil))

	if len(c.http.Jar.Cookies(cookieURL)) == 0 {
		if err := c.LoginCtx(ctx); err != nil {
			return nil, errors.Wrap(err, "qbit re-login failed")
		}
	}

	// try request and if fail run 10 retries
	resp, err := c.retryDo(ctx, req)
	if err != nil {
		return nil, errors.Wrap(err, "error making get request: %v", reqUrl)
	}

	return resp, nil
}

func (c *Client) postCtx(ctx context.Context, endpoint string, opts map[string]string) (*http.Response, error) {
	// add optional parameters that the user wants
	form := url.Values{}
	for k, v := range opts {
		form.Add(k, v)
	}

	reqUrl := c.buildUrl(endpoint, nil)

	req, err := http.NewRequestWithContext(ctx, http.MethodPost, reqUrl, strings.NewReader(form.Encode()))
	if err != nil {
		return nil, errors.Wrap(err, "could not build request")
	}

	if c.cfg.BasicUser != "" && c.cfg.BasicPass != "" {
		req.SetBasicAuth(c.cfg.BasicUser, c.cfg.BasicPass)
	}

	// add the content-type so qbittorrent knows what to expect
	req.Header.Add("Content-Type", "application/x-www-form-urlencoded")

	cookieURL, _ := url.Parse(c.buildUrl("/", nil))
	if len(c.http.Jar.Cookies(cookieURL)) == 0 {
		if err := c.LoginCtx(ctx); err != nil {
			return nil, errors.Wrap(err, "qbit re-login failed")
		}
	}

	// try request and if fail run 10 retries
	resp, err := c.retryDo(ctx, req)
	if err != nil {
		return nil, errors.Wrap(err, "error making post request: %v", reqUrl)
	}

	return resp, nil
}

func (c *Client) postBasicCtx(ctx context.Context, endpoint string, opts map[string]string) (*http.Response, error) {
	// add optional parameters that the user wants
	form := url.Values{}
	for k, v := range opts {
		form.Add(k, v)
	}

	var resp *http.Response

	reqUrl := c.buildUrl(endpoint, nil)

	req, err := http.NewRequestWithContext(ctx, http.MethodPost, reqUrl, strings.NewReader(form.Encode()))
	if err != nil {
		return nil, errors.Wrap(err, "could not build request")
	}

	if c.cfg.BasicUser != "" && c.cfg.BasicPass != "" {
		req.SetBasicAuth(c.cfg.BasicUser, c.cfg.BasicPass)
	}

	// add the content-type so qbittorrent knows what to expect
	req.Header.Add("Content-Type", "application/x-www-form-urlencoded")

	resp, err = c.http.Do(req)
	if err != nil {
		return nil, errors.Wrap(err, "error making post request: %v", reqUrl)
	}

	return resp, nil
}

func (c *Client) postFileCtx(ctx context.Context, endpoint string, fileName string, opts map[string]string) (*http.Response, error) {
	b, err := os.ReadFile(fileName)
	if err != nil {
		return nil, errors.Wrap(err, "error reading file %v", fileName)
	}

	return c.postMemoryCtx(ctx, endpoint, b, opts)
}

func (c *Client) postMemoryCtx(ctx context.Context, endpoint string, buf []byte, opts map[string]string) (*http.Response, error) {
	// Buffer to store our request body as bytes
	var requestBody bytes.Buffer

	// Store a multipart writer
	multiPartWriter := multipart.NewWriter(&requestBody)
	torName := generateTorrentName()

	// Initialize file field
	fileWriter, err := multiPartWriter.CreateFormFile("torrents", torName)
	if err != nil {
		return nil, errors.Wrap(err, "error initializing file field")
	}

	// Copy the actual file content to the fields writer
	if _, err := io.Copy(fileWriter, bytes.NewBuffer(buf)); err != nil {
		return nil, errors.Wrap(err, "error copy file contents to writer")
	}

	// Populate other fields
	for key, val := range opts {
		fieldWriter, err := multiPartWriter.CreateFormField(key)
		if err != nil {
			return nil, errors.Wrap(err, "error creating form field %v with value %v", key, val)
		}

		if _, err := fieldWriter.Write([]byte(val)); err != nil {
			return nil, errors.Wrap(err, "error writing field %v with value %v", key, val)
		}
	}

	// Close multipart writer
	contentType := multiPartWriter.FormDataContentType()
	multiPartWriter.Close()

	reqUrl := c.buildUrl(endpoint, nil)
	req, err := http.NewRequestWithContext(ctx, http.MethodPost, reqUrl, &requestBody)
	if err != nil {
		return nil, errors.Wrap(err, "error creating request")
	}

	if c.cfg.BasicUser != "" && c.cfg.BasicPass != "" {
		req.SetBasicAuth(c.cfg.BasicUser, c.cfg.BasicPass)
	}

	// Set correct content type
	req.Header.Set("Content-Type", contentType)

	cookieURL, _ := url.Parse(c.buildUrl("/", nil))
	if len(c.http.Jar.Cookies(cookieURL)) == 0 {
		if err := c.LoginCtx(ctx); err != nil {
			return nil, errors.Wrap(err, "qbit re-login failed")
		}
	}

	resp, err := c.retryDo(ctx, req)
	if err != nil {
		return nil, errors.Wrap(err, "error making post file request")
	}

	return resp, nil
}

func generateTorrentName() string {
	// A simple string generator for supplying multipart form fields
	// Presently with the API this does not matter, but may be used for internal context
	// if it ever becomes a problem, feel no qualms about removing it.
	z := []byte{'Q', 'W', 'E', 'R', 'T', 'Y', 'U', 'I', 'O', 'P', 'A', 'S', 'D', 'F', 'G', 'H', 'J', 'K', 'L', 'Z', 'X', 'C', 'V', 'B', 'N', 'M', 'q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p', 'a', 's', 'd', 'f', 'g', 'h', 'j', 'k', 'l', 'z', 'x', 'c', 'v', 'b', 'n', 'm', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '_'}
	s := make([]byte, 16)
	for i := 0; i < len(s); i++ {
		s[i] = z[rand.Intn(len(z)-1)]
	}

	return string(s)
}

func (c *Client) setCookies(cookies []*http.Cookie) {
	cookieURL, _ := url.Parse(c.buildUrl("/", nil))

	c.http.Jar.SetCookies(cookieURL, cookies)
}

func (c *Client) buildUrl(endpoint string, params map[string]string) string {
	apiBase := "/api/v2/"

	// add query params
	queryParams := url.Values{}
	for key, value := range params {
		queryParams.Add(key, value)
	}

	joinedUrl, _ := url.JoinPath(c.cfg.Host, apiBase, endpoint)
	parsedUrl, _ := url.Parse(joinedUrl)
	parsedUrl.RawQuery = queryParams.Encode()

	// make into new string and return
	return parsedUrl.String()
}

func copyBody(src io.ReadCloser) ([]byte, error) {
	b, err := io.ReadAll(src)
	if err != nil {
		// ErrReadingRequestBody
		return nil, err
	}
	src.Close()
	return b, nil
}

func resetBody(request *http.Request, originalBody []byte) {
	request.Body = io.NopCloser(bytes.NewBuffer(originalBody))
	request.GetBody = func() (io.ReadCloser, error) {
		return io.NopCloser(bytes.NewBuffer(originalBody)), nil
	}
}

func (c *Client) retryDo(ctx context.Context, req *http.Request) (*http.Response, error) {
	var (
		originalBody []byte
		err          error
	)

	if req != nil && req.Body != nil {
		originalBody, err = copyBody(req.Body)
	}

	if err != nil {
		return nil, err
	}

	var resp *http.Response

	// try request and if fail run 10 retries
	err = retry.Do(func() error {
		if req != nil && req.Body != nil {
			resetBody(req, originalBody)
		}

		resp, err = c.http.Do(req)

		if err == nil {
			if resp.StatusCode == http.StatusForbidden {
				if err := c.LoginCtx(ctx); err != nil {
					return errors.Wrap(err, "qbit re-login failed")
				}

				retry.Delay(100 * time.Millisecond)

				return errors.New("qbit re-login")
			} else if resp.StatusCode < 500 {
				return err
			} else if resp.StatusCode >= 500 {
				return retry.Unrecoverable(errors.New("unrecoverable status: %v", resp.StatusCode))
			}
		}

		retry.Delay(time.Second * 3)

		return err
	},
		retry.OnRetry(func(n uint, err error) { c.log.Printf("%q: attempt %d - %v\n", err, n, req.URL.String()) }),
		//retry.Delay(time.Second*3),
		retry.Attempts(5),
		retry.MaxJitter(time.Second*1),
	)

	if err != nil {
		return nil, errors.Wrap(err, "error making request")
	}

	return resp, nil
}
</file>

<file path="go.mod">
module github.com/autobrr/go-qbittorrent

go 1.24

toolchain go1.24.1

require (
	github.com/Masterminds/semver v1.5.0
	github.com/avast/retry-go v3.0.0+incompatible
	github.com/pkg/errors v0.9.1
	github.com/stretchr/testify v1.10.0
	golang.org/x/exp v0.0.0-20241108190413-2d47ceb2692f
	golang.org/x/net v0.40.0
)

require (
	github.com/davecgh/go-spew v1.1.1 // indirect
	github.com/pmezard/go-difflib v1.0.0 // indirect
	gopkg.in/yaml.v3 v3.0.1 // indirect
)
</file>

<file path="domain.go">
package qbittorrent

import (
	"strconv"

	"github.com/autobrr/go-qbittorrent/errors"
)

var (
	ErrBadCredentials = errors.New("bad credentials")
	ErrIPBanned       = errors.New("User's IP is banned for too many failed login attempts")

	ErrUnexpectedStatus = errors.New("unexpected status code")

	ErrNoTorrentURLProvided           = errors.New("no torrent URL provided")
	ErrEmptySavePath                  = errors.New("save path is empty")
	ErrNoWriteAccessToPath            = errors.New("user does not have write access to directory")
	ErrCannotCreateSavePath           = errors.New("unable to create save path directory")
	ErrEmptyCategoryName              = errors.New("category name is empty")
	ErrInvalidCategoryName            = errors.New("category name is invalid")
	ErrCategoryEditingFailed          = errors.New("category editing failed")
	ErrCategoryDoesNotExist           = errors.New("category name does not exist")
	ErrInvalidPriority                = errors.New("priority is invalid or at least one id is not an integer")
	ErrTorrentNotFound                = errors.New("torrent not found")
	ErrTorrentMetdataNotDownloadedYet = errors.New("torrent metadata hasn't downloaded yet or at least one file id was not found")
	ErrMissingNewPathParameter        = errors.New("missing newPath parameter")
	ErrInvalidPathParameter           = errors.New("invalid newPath or oldPath, or newPath already in use")
	ErrInvalidTorrentHash             = errors.New("torrent hash is invalid")
	ErrEmptyTorrentName               = errors.New("torrent name is empty")
	ErrAllURLsNotFound                = errors.New("all urls were not found")
	ErrInvalidURL                     = errors.New("new url is not a valid URL")
	ErrTorrentQueueingNotEnabled      = errors.New("torrent queueing is not enabled, could not set hashes to max priority")
	ErrInvalidShareLimit              = errors.New("a share limit or at least one id is invalid")
	ErrInvalidCookies                 = errors.New("request was not a valid json array of cookie objects")
	ErrCannotGetTorrentPieceStates    = errors.New("could not get torrent piece states")
	ErrInvalidPeers                   = errors.New("none of the supplied peers are valid")

	ErrReannounceTookTooLong = errors.New("reannounce took too long, deleted torrent")
	ErrUnsupportedVersion    = errors.New("qBittorrent version too old, please upgrade to use this feature")
)

type Torrent struct {
	AddedOn            int64            `json:"added_on"`
	AmountLeft         int64            `json:"amount_left"`
	AutoManaged        bool             `json:"auto_tmm"`
	Availability       float64          `json:"availability"`
	Category           string           `json:"category"`
	Completed          int64            `json:"completed"`
	CompletionOn       int64            `json:"completion_on"`
	ContentPath        string           `json:"content_path"`
	DlLimit            int64            `json:"dl_limit"`
	DlSpeed            int64            `json:"dlspeed"`
	DownloadPath       string           `json:"download_path"`
	Downloaded         int64            `json:"downloaded"`
	DownloadedSession  int64            `json:"downloaded_session"`
	ETA                int64            `json:"eta"`
	FirstLastPiecePrio bool             `json:"f_l_piece_prio"`
	ForceStart         bool             `json:"force_start"`
	Hash               string           `json:"hash"`
	InfohashV1         string           `json:"infohash_v1"`
	InfohashV2         string           `json:"infohash_v2"`
	LastActivity       int64            `json:"last_activity"`
	MagnetURI          string           `json:"magnet_uri"`
	MaxRatio           float64          `json:"max_ratio"`
	MaxSeedingTime     int64            `json:"max_seeding_time"`
	Name               string           `json:"name"`
	NumComplete        int64            `json:"num_complete"`
	NumIncomplete      int64            `json:"num_incomplete"`
	NumLeechs          int64            `json:"num_leechs"`
	NumSeeds           int64            `json:"num_seeds"`
	Priority           int64            `json:"priority"`
	Progress           float64          `json:"progress"`
	Ratio              float64          `json:"ratio"`
	RatioLimit         float64          `json:"ratio_limit"`
	SavePath           string           `json:"save_path"`
	SeedingTime        int64            `json:"seeding_time"`
	SeedingTimeLimit   int64            `json:"seeding_time_limit"`
	SeenComplete       int64            `json:"seen_complete"`
	SequentialDownload bool             `json:"seq_dl"`
	Size               int64            `json:"size"`
	State              TorrentState     `json:"state"`
	SuperSeeding       bool             `json:"super_seeding"`
	Tags               string           `json:"tags"`
	TimeActive         int64            `json:"time_active"`
	TotalSize          int64            `json:"total_size"`
	Tracker            string           `json:"tracker"`
	TrackersCount      int64            `json:"trackers_count"`
	UpLimit            int64            `json:"up_limit"`
	Uploaded           int64            `json:"uploaded"`
	UploadedSession    int64            `json:"uploaded_session"`
	UpSpeed            int64            `json:"upspeed"`
	Trackers           []TorrentTracker `json:"trackers"`
}

type TorrentTrackersResponse struct {
	Trackers []TorrentTracker `json:"trackers"`
}

type TorrentTracker struct {
	// Tier          int   `json:"tier"` // can be both empty "" and int
	Url           string        `json:"url"`
	Status        TrackerStatus `json:"status"`
	NumPeers      int           `json:"num_peers"`
	NumSeeds      int           `json:"num_seeds"`
	NumLeechers   int           `json:"num_leechers"`
	NumDownloaded int           `json:"num_downloaded"`
	Message       string        `json:"msg"`
}

type TorrentFiles []struct {
	Availability float32 `json:"availability"`
	Index        int     `json:"index"`
	IsSeed       bool    `json:"is_seed,omitempty"`
	Name         string  `json:"name"`
	PieceRange   []int   `json:"piece_range"`
	Priority     int     `json:"priority"`
	Progress     float32 `json:"progress"`
	Size         int64   `json:"size"`
}

type Category struct {
	Name     string `json:"name"`
	SavePath string `json:"savePath"`
}

type TorrentState string

const (
	// Some error occurred, applies to paused torrents
	TorrentStateError TorrentState = "error"

	// Torrent data files is missing
	TorrentStateMissingFiles TorrentState = "missingFiles"

	// Torrent is being seeded and data is being transferred
	TorrentStateUploading TorrentState = "uploading"

	// Torrent is paused and has finished downloading
	TorrentStatePausedUp TorrentState = "pausedUP"

	// Torrent is stopped and has finished downloading
	TorrentStateStoppedUp TorrentState = "stoppedUP"

	// Queuing is enabled and torrent is queued for upload
	TorrentStateQueuedUp TorrentState = "queuedUP"

	// Torrent is being seeded, but no connection were made
	TorrentStateStalledUp TorrentState = "stalledUP"

	// Torrent has finished downloading and is being checked
	TorrentStateCheckingUp TorrentState = "checkingUP"

	// Torrent is forced to uploading and ignore queue limit
	TorrentStateForcedUp TorrentState = "forcedUP"

	// Torrent is allocating disk space for download
	TorrentStateAllocating TorrentState = "allocating"

	// Torrent is being downloaded and data is being transferred
	TorrentStateDownloading TorrentState = "downloading"

	// Torrent has just started downloading and is fetching metadata
	TorrentStateMetaDl TorrentState = "metaDL"

	// Torrent is paused and has NOT finished downloading
	TorrentStatePausedDl TorrentState = "pausedDL"

	// Torrent is stopped and has NOT finished downloading
	TorrentStateStoppedDl TorrentState = "stoppedDL"

	// Queuing is enabled and torrent is queued for download
	TorrentStateQueuedDl TorrentState = "queuedDL"

	// Torrent is being downloaded, but no connection were made
	TorrentStateStalledDl TorrentState = "stalledDL"

	// Same as checkingUP, but torrent has NOT finished downloading
	TorrentStateCheckingDl TorrentState = "checkingDL"

	// Torrent is forced to downloading to ignore queue limit
	TorrentStateForcedDl TorrentState = "forcedDL"

	// Checking resume data on qBt startup
	TorrentStateCheckingResumeData TorrentState = "checkingResumeData"

	// Torrent is moving to another location
	TorrentStateMoving TorrentState = "moving"

	// Unknown status
	TorrentStateUnknown TorrentState = "unknown"
)

type TorrentFilter string

const (
	// Torrent is paused
	TorrentFilterAll TorrentFilter = "all"

	// Torrent is active
	TorrentFilterActive TorrentFilter = "active"

	// Torrent is inactive
	TorrentFilterInactive TorrentFilter = "inactive"

	// Torrent is completed
	TorrentFilterCompleted TorrentFilter = "completed"

	// Torrent is resumed
	TorrentFilterResumed TorrentFilter = "resumed"

	// Torrent is paused
	TorrentFilterPaused TorrentFilter = "paused"

	// Torrent is stopped
	TorrentFilterStopped TorrentFilter = "stopped"

	// Torrent is stalled
	TorrentFilterStalled TorrentFilter = "stalled"

	// Torrent is being seeded and data is being transferred
	TorrentFilterUploading TorrentFilter = "uploading"

	// Torrent is being seeded, but no connection were made
	TorrentFilterStalledUploading TorrentFilter = "stalled_uploading"

	// Torrent is being downloaded and data is being transferred
	TorrentFilterDownloading TorrentFilter = "downloading"

	// Torrent is being downloaded, but no connection were made
	TorrentFilterStalledDownloading TorrentFilter = "stalled_downloading"

	// Torrent is errored
	TorrentFilterError TorrentFilter = "errored"
)

// TrackerStatus https://github.com/qbittorrent/qBittorrent/wiki/WebUI-API-(qBittorrent-4.1)#get-torrent-trackers
type TrackerStatus int

const (
	// 0 Tracker is disabled (used for DHT, PeX, and LSD)
	TrackerStatusDisabled TrackerStatus = 0

	// 1 Tracker has not been contacted yet
	TrackerStatusNotContacted TrackerStatus = 1

	// 2 Tracker has been contacted and is working
	TrackerStatusOK TrackerStatus = 2

	// 3 Tracker is updating
	TrackerStatusUpdating TrackerStatus = 3

	// 4 Tracker has been contacted, but it is not working (or doesn't send proper replies)
	TrackerStatusNotWorking TrackerStatus = 4
)

type ConnectionStatus string

const (
	ConnectionStatusConnected    = "connected"
	ConnectionStatusFirewalled   = "firewalled"
	ConnectionStatusDisconnected = "disconnected"
)

// TransferInfo
//
// https://github.com/qbittorrent/qBittorrent/wiki/WebUI-API-(qBittorrent-4.1)#get-global-transfer-info
//
// dl_info_speed 		integer 	Global download rate (bytes/s)
//
// dl_info_data 		integer 	Data downloaded this session (bytes)
//
// up_info_speed 		integer 	Global upload rate (bytes/s)
//
// up_info_data 		integer 	Data uploaded this session (bytes)
//
// dl_rate_limit 		integer 	Download rate limit (bytes/s)
//
// up_rate_limit 		integer 	Upload rate limit (bytes/s)
//
// dht_nodes 			integer 	DHT nodes connected to
//
// connection_status 	string 		Connection status. See possible values here below
type TransferInfo struct {
	ConnectionStatus ConnectionStatus `json:"connection_status"`
	DHTNodes         int64            `json:"dht_nodes"`
	DlInfoData       int64            `json:"dl_info_data"`
	DlInfoSpeed      int64            `json:"dl_info_speed"`
	DlRateLimit      int64            `json:"dl_rate_limit"`
	UpInfoData       int64            `json:"up_info_data"`
	UpInfoSpeed      int64            `json:"up_info_speed"`
	UpRateLimit      int64            `json:"up_rate_limit"`
}

type ContentLayout string

const (
	ContentLayoutOriginal        ContentLayout = "Original"
	ContentLayoutSubfolderNone   ContentLayout = "NoSubfolder"
	ContentLayoutSubfolderCreate ContentLayout = "Subfolder"
)

type TorrentAddOptions struct {
	Stopped            bool // introduced in Web API v2.11.0 (v5.0.0)
	Paused             bool
	SkipHashCheck      bool
	ContentLayout      ContentLayout
	SavePath           string
	AutoTMM            bool
	Category           string
	Tags               string
	LimitUploadSpeed   int64
	LimitDownloadSpeed int64
	LimitRatio         float64
	LimitSeedTime      int64
	Rename             string
	FirstLastPiecePrio bool
	SequentialDownload bool
}

func (o *TorrentAddOptions) Prepare() map[string]string {
	options := map[string]string{}

	options["paused"] = "false"
	options["stopped"] = "false"
	if o.Paused {
		options["paused"] = "true"
		options["stopped"] = "true"
	}
	if o.Stopped {
		options["paused"] = "true"
		options["stopped"] = "true"
	}
	if o.SkipHashCheck {
		options["skip_checking"] = "true"
	}

	if o.ContentLayout == ContentLayoutSubfolderCreate {
		// pre qBittorrent version 4.3.2
		options["root_folder"] = "true"

		// post version 4.3.2
		options["contentLayout"] = string(ContentLayoutSubfolderCreate)

	} else if o.ContentLayout == ContentLayoutSubfolderNone {
		// pre qBittorrent version 4.3.2
		options["root_folder"] = "false"

		// post version 4.3.2
		options["contentLayout"] = string(ContentLayoutSubfolderNone)
	}
	// if ORIGINAL then leave empty

	if o.SavePath != "" {
		options["savepath"] = o.SavePath
		options["autoTMM"] = "false"
	}
	if o.Category != "" {
		options["category"] = o.Category
	}
	if o.Tags != "" {
		options["tags"] = o.Tags
	}
	if o.LimitUploadSpeed > 0 {
		options["upLimit"] = strconv.FormatInt(o.LimitUploadSpeed*1024, 10)
	}
	if o.LimitDownloadSpeed > 0 {
		options["dlLimit"] = strconv.FormatInt(o.LimitDownloadSpeed*1024, 10)
	}
	if o.LimitRatio > 0 {
		options["ratioLimit"] = strconv.FormatFloat(o.LimitRatio, 'f', 2, 64)
	}
	if o.LimitSeedTime > 0 {
		options["seedingTimeLimit"] = strconv.FormatInt(o.LimitSeedTime, 10)
	}

	if o.Rename != "" {
		options["rename"] = o.Rename
	}

	options["firstLastPiecePrio"] = strconv.FormatBool(o.FirstLastPiecePrio)

	if o.SequentialDownload {
		options["sequentialDownload"] = "true"
	}

	return options
}

type TorrentFilterOptions struct {
	Filter          TorrentFilter
	Category        string
	Tag             string
	Sort            string
	Reverse         bool
	Limit           int
	Offset          int
	Hashes          []string
	IncludeTrackers bool // qbit 5.1+
}

type TorrentProperties struct {
	AdditionDate           int     `json:"addition_date"`
	Comment                string  `json:"comment"`
	CompletionDate         int     `json:"completion_date"`
	CreatedBy              string  `json:"created_by"`
	CreationDate           int     `json:"creation_date"`
	DlLimit                int     `json:"dl_limit"`
	DlSpeed                int     `json:"dl_speed"`
	DlSpeedAvg             int     `json:"dl_speed_avg"`
	DownloadPath           string  `json:"download_path"`
	Eta                    int     `json:"eta"`
	Hash                   string  `json:"hash"`
	InfohashV1             string  `json:"infohash_v1"`
	InfohashV2             string  `json:"infohash_v2"`
	IsPrivate              bool    `json:"is_private"`
	LastSeen               int     `json:"last_seen"`
	Name                   string  `json:"name"`
	NbConnections          int     `json:"nb_connections"`
	NbConnectionsLimit     int     `json:"nb_connections_limit"`
	Peers                  int     `json:"peers"`
	PeersTotal             int     `json:"peers_total"`
	PieceSize              int     `json:"piece_size"`
	PiecesHave             int     `json:"pieces_have"`
	PiecesNum              int     `json:"pieces_num"`
	Reannounce             int     `json:"reannounce"`
	SavePath               string  `json:"save_path"`
	SeedingTime            int     `json:"seeding_time"`
	Seeds                  int     `json:"seeds"`
	SeedsTotal             int     `json:"seeds_total"`
	ShareRatio             float64 `json:"share_ratio"`
	TimeElapsed            int     `json:"time_elapsed"`
	TotalDownloaded        int64   `json:"total_downloaded"`
	TotalDownloadedSession int64   `json:"total_downloaded_session"`
	TotalSize              int64   `json:"total_size"`
	TotalUploaded          int64   `json:"total_uploaded"`
	TotalUploadedSession   int64   `json:"total_uploaded_session"`
	TotalWasted            int64   `json:"total_wasted"`
	UpLimit                int     `json:"up_limit"`
	UpSpeed                int     `json:"up_speed"`
	UpSpeedAvg             int     `json:"up_speed_avg"`
}

type AppPreferences struct {
	AddTrackers                      string      `json:"add_trackers"`
	AddTrackersEnabled               bool        `json:"add_trackers_enabled"`
	AltDlLimit                       int         `json:"alt_dl_limit"`
	AltUpLimit                       int         `json:"alt_up_limit"`
	AlternativeWebuiEnabled          bool        `json:"alternative_webui_enabled"`
	AlternativeWebuiPath             string      `json:"alternative_webui_path"`
	AnnounceIP                       string      `json:"announce_ip"`
	AnnounceToAllTiers               bool        `json:"announce_to_all_tiers"`
	AnnounceToAllTrackers            bool        `json:"announce_to_all_trackers"`
	AnonymousMode                    bool        `json:"anonymous_mode"`
	AsyncIoThreads                   int         `json:"async_io_threads"`
	AutoDeleteMode                   int         `json:"auto_delete_mode"`
	AutoTmmEnabled                   bool        `json:"auto_tmm_enabled"`
	AutorunEnabled                   bool        `json:"autorun_enabled"`
	AutorunOnTorrentAddedEnabled     bool        `json:"autorun_on_torrent_added_enabled"`
	AutorunOnTorrentAddedProgram     string      `json:"autorun_on_torrent_added_program"`
	AutorunProgram                   string      `json:"autorun_program"`
	BannedIPs                        string      `json:"banned_IPs"`
	BittorrentProtocol               int         `json:"bittorrent_protocol"`
	BlockPeersOnPrivilegedPorts      bool        `json:"block_peers_on_privileged_ports"`
	BypassAuthSubnetWhitelist        string      `json:"bypass_auth_subnet_whitelist"`
	BypassAuthSubnetWhitelistEnabled bool        `json:"bypass_auth_subnet_whitelist_enabled"`
	BypassLocalAuth                  bool        `json:"bypass_local_auth"`
	CategoryChangedTmmEnabled        bool        `json:"category_changed_tmm_enabled"`
	CheckingMemoryUse                int         `json:"checking_memory_use"`
	ConnectionSpeed                  int         `json:"connection_speed"`
	CurrentInterfaceAddress          string      `json:"current_interface_address"`
	CurrentNetworkInterface          string      `json:"current_network_interface"`
	Dht                              bool        `json:"dht"`
	DiskCache                        int         `json:"disk_cache"`
	DiskCacheTTL                     int         `json:"disk_cache_ttl"`
	DiskIoReadMode                   int         `json:"disk_io_read_mode"`
	DiskIoType                       int         `json:"disk_io_type"`
	DiskIoWriteMode                  int         `json:"disk_io_write_mode"`
	DiskQueueSize                    int         `json:"disk_queue_size"`
	DlLimit                          int         `json:"dl_limit"`
	DontCountSlowTorrents            bool        `json:"dont_count_slow_torrents"`
	DyndnsDomain                     string      `json:"dyndns_domain"`
	DyndnsEnabled                    bool        `json:"dyndns_enabled"`
	DyndnsPassword                   string      `json:"dyndns_password"`
	DyndnsService                    int         `json:"dyndns_service"`
	DyndnsUsername                   string      `json:"dyndns_username"`
	EmbeddedTrackerPort              int         `json:"embedded_tracker_port"`
	EmbeddedTrackerPortForwarding    bool        `json:"embedded_tracker_port_forwarding"`
	EnableCoalesceReadWrite          bool        `json:"enable_coalesce_read_write"`
	EnableEmbeddedTracker            bool        `json:"enable_embedded_tracker"`
	EnableMultiConnectionsFromSameIP bool        `json:"enable_multi_connections_from_same_ip"`
	EnablePieceExtentAffinity        bool        `json:"enable_piece_extent_affinity"`
	EnableUploadSuggestions          bool        `json:"enable_upload_suggestions"`
	Encryption                       int         `json:"encryption"`
	ExcludedFileNames                string      `json:"excluded_file_names"`
	ExcludedFileNamesEnabled         bool        `json:"excluded_file_names_enabled"`
	ExportDir                        string      `json:"export_dir"`
	ExportDirFin                     string      `json:"export_dir_fin"`
	FilePoolSize                     int         `json:"file_pool_size"`
	HashingThreads                   int         `json:"hashing_threads"`
	IdnSupportEnabled                bool        `json:"idn_support_enabled"`
	IncompleteFilesExt               bool        `json:"incomplete_files_ext"`
	IPFilterEnabled                  bool        `json:"ip_filter_enabled"`
	IPFilterPath                     string      `json:"ip_filter_path"`
	IPFilterTrackers                 bool        `json:"ip_filter_trackers"`
	LimitLanPeers                    bool        `json:"limit_lan_peers"`
	LimitTCPOverhead                 bool        `json:"limit_tcp_overhead"`
	LimitUtpRate                     bool        `json:"limit_utp_rate"`
	ListenPort                       int         `json:"listen_port"`
	Locale                           string      `json:"locale"`
	Lsd                              bool        `json:"lsd"`
	MailNotificationAuthEnabled      bool        `json:"mail_notification_auth_enabled"`
	MailNotificationEmail            string      `json:"mail_notification_email"`
	MailNotificationEnabled          bool        `json:"mail_notification_enabled"`
	MailNotificationPassword         string      `json:"mail_notification_password"`
	MailNotificationSender           string      `json:"mail_notification_sender"`
	MailNotificationSMTP             string      `json:"mail_notification_smtp"`
	MailNotificationSslEnabled       bool        `json:"mail_notification_ssl_enabled"`
	MailNotificationUsername         string      `json:"mail_notification_username"`
	MaxActiveCheckingTorrents        int         `json:"max_active_checking_torrents"`
	MaxActiveDownloads               int         `json:"max_active_downloads"`
	MaxActiveTorrents                int         `json:"max_active_torrents"`
	MaxActiveUploads                 int         `json:"max_active_uploads"`
	MaxConcurrentHTTPAnnounces       int         `json:"max_concurrent_http_announces"`
	MaxConnec                        int         `json:"max_connec"`
	MaxConnecPerTorrent              int         `json:"max_connec_per_torrent"`
	MaxRatio                         float64     `json:"max_ratio"`
	MaxRatioAct                      int         `json:"max_ratio_act"`
	MaxRatioEnabled                  bool        `json:"max_ratio_enabled"`
	MaxSeedingTime                   int         `json:"max_seeding_time"`
	MaxSeedingTimeEnabled            bool        `json:"max_seeding_time_enabled"`
	MaxUploads                       int         `json:"max_uploads"`
	MaxUploadsPerTorrent             int         `json:"max_uploads_per_torrent"`
	MemoryWorkingSetLimit            int         `json:"memory_working_set_limit"`
	OutgoingPortsMax                 int         `json:"outgoing_ports_max"`
	OutgoingPortsMin                 int         `json:"outgoing_ports_min"`
	PeerTos                          int         `json:"peer_tos"`
	PeerTurnover                     int         `json:"peer_turnover"`
	PeerTurnoverCutoff               int         `json:"peer_turnover_cutoff"`
	PeerTurnoverInterval             int         `json:"peer_turnover_interval"`
	PerformanceWarning               bool        `json:"performance_warning"`
	Pex                              bool        `json:"pex"`
	PreallocateAll                   bool        `json:"preallocate_all"`
	ProxyAuthEnabled                 bool        `json:"proxy_auth_enabled"`
	ProxyHostnameLookup              bool        `json:"proxy_hostname_lookup"`
	ProxyIP                          string      `json:"proxy_ip"`
	ProxyPassword                    string      `json:"proxy_password"`
	ProxyPeerConnections             bool        `json:"proxy_peer_connections"`
	ProxyPort                        int         `json:"proxy_port"`
	ProxyTorrentsOnly                bool        `json:"proxy_torrents_only"`
	ProxyType                        interface{} `json:"proxy_type"` // pre 4.5.x this is an int and post 4.6.x it's a string
	ProxyUsername                    string      `json:"proxy_username"`
	QueueingEnabled                  bool        `json:"queueing_enabled"`
	RandomPort                       bool        `json:"random_port"`
	ReannounceWhenAddressChanged     bool        `json:"reannounce_when_address_changed"`
	RecheckCompletedTorrents         bool        `json:"recheck_completed_torrents"`
	RefreshInterval                  int         `json:"refresh_interval"`
	RequestQueueSize                 int         `json:"request_queue_size"`
	ResolvePeerCountries             bool        `json:"resolve_peer_countries"`
	ResumeDataStorageType            string      `json:"resume_data_storage_type"`
	RssAutoDownloadingEnabled        bool        `json:"rss_auto_downloading_enabled"`
	RssDownloadRepackProperEpisodes  bool        `json:"rss_download_repack_proper_episodes"`
	RssMaxArticlesPerFeed            int         `json:"rss_max_articles_per_feed"`
	RssProcessingEnabled             bool        `json:"rss_processing_enabled"`
	RssRefreshInterval               int         `json:"rss_refresh_interval"`
	RssSmartEpisodeFilters           string      `json:"rss_smart_episode_filters"`
	SavePath                         string      `json:"save_path"`
	SavePathChangedTmmEnabled        bool        `json:"save_path_changed_tmm_enabled"`
	SaveResumeDataInterval           int         `json:"save_resume_data_interval"`
	ScanDirs                         struct {
	} `json:"scan_dirs"`
	ScheduleFromHour                   int    `json:"schedule_from_hour"`
	ScheduleFromMin                    int    `json:"schedule_from_min"`
	ScheduleToHour                     int    `json:"schedule_to_hour"`
	ScheduleToMin                      int    `json:"schedule_to_min"`
	SchedulerDays                      int    `json:"scheduler_days"`
	SchedulerEnabled                   bool   `json:"scheduler_enabled"`
	SendBufferLowWatermark             int    `json:"send_buffer_low_watermark"`
	SendBufferWatermark                int    `json:"send_buffer_watermark"`
	SendBufferWatermarkFactor          int    `json:"send_buffer_watermark_factor"`
	SlowTorrentDlRateThreshold         int    `json:"slow_torrent_dl_rate_threshold"`
	SlowTorrentInactiveTimer           int    `json:"slow_torrent_inactive_timer"`
	SlowTorrentUlRateThreshold         int    `json:"slow_torrent_ul_rate_threshold"`
	SocketBacklogSize                  int    `json:"socket_backlog_size"`
	SsrfMitigation                     bool   `json:"ssrf_mitigation"`
	StartPausedEnabled                 bool   `json:"start_paused_enabled"`
	StopTrackerTimeout                 int    `json:"stop_tracker_timeout"`
	TempPath                           string `json:"temp_path"`
	TempPathEnabled                    bool   `json:"temp_path_enabled"`
	TorrentChangedTmmEnabled           bool   `json:"torrent_changed_tmm_enabled"`
	TorrentContentLayout               string `json:"torrent_content_layout"`
	TorrentStopCondition               string `json:"torrent_stop_condition"`
	UpLimit                            int    `json:"up_limit"`
	UploadChokingAlgorithm             int    `json:"upload_choking_algorithm"`
	UploadSlotsBehavior                int    `json:"upload_slots_behavior"`
	Upnp                               bool   `json:"upnp"`
	UpnpLeaseDuration                  int    `json:"upnp_lease_duration"`
	UseCategoryPathsInManualMode       bool   `json:"use_category_paths_in_manual_mode"`
	UseHTTPS                           bool   `json:"use_https"`
	UtpTCPMixedMode                    int    `json:"utp_tcp_mixed_mode"`
	ValidateHTTPSTrackerCertificate    bool   `json:"validate_https_tracker_certificate"`
	WebUIAddress                       string `json:"web_ui_address"`
	WebUIBanDuration                   int    `json:"web_ui_ban_duration"`
	WebUIClickjackingProtectionEnabled bool   `json:"web_ui_clickjacking_protection_enabled"`
	WebUICsrfProtectionEnabled         bool   `json:"web_ui_csrf_protection_enabled"`
	WebUICustomHTTPHeaders             string `json:"web_ui_custom_http_headers"`
	WebUIDomainList                    string `json:"web_ui_domain_list"`
	WebUIHostHeaderValidationEnabled   bool   `json:"web_ui_host_header_validation_enabled"`
	WebUIHTTPSCertPath                 string `json:"web_ui_https_cert_path"`
	WebUIHTTPSKeyPath                  string `json:"web_ui_https_key_path"`
	WebUIMaxAuthFailCount              int    `json:"web_ui_max_auth_fail_count"`
	WebUIPort                          int    `json:"web_ui_port"`
	WebUIReverseProxiesList            string `json:"web_ui_reverse_proxies_list"`
	WebUIReverseProxyEnabled           bool   `json:"web_ui_reverse_proxy_enabled"`
	WebUISecureCookieEnabled           bool   `json:"web_ui_secure_cookie_enabled"`
	WebUISessionTimeout                int    `json:"web_ui_session_timeout"`
	WebUIUpnp                          bool   `json:"web_ui_upnp"`
	WebUIUseCustomHTTPHeadersEnabled   bool   `json:"web_ui_use_custom_http_headers_enabled"`
	WebUIUsername                      string `json:"web_ui_username"`
}

type MainData struct {
	Rid               int64               `json:"rid"`
	FullUpdate        bool                `json:"full_update"`
	Torrents          map[string]Torrent  `json:"torrents"`
	TorrentsRemoved   []string            `json:"torrents_removed"`
	Categories        map[string]Category `json:"categories"`
	CategoriesRemoved []string            `json:"categories_removed"`
	Tags              []string            `json:"tags"`
	TagsRemoved       []string            `json:"tags_removed"`
	Trackers          map[string][]string `json:"trackers"`
	ServerState       ServerState         `json:"server_state"`
}

type ServerState struct {
	AlltimeDl            int64  `json:"alltime_dl"`
	AlltimeUl            int64  `json:"alltime_ul"`
	AverageTimeQueue     int64  `json:"average_time_queue"`
	ConnectionStatus     string `json:"connection_status"`
	DhtNodes             int64  `json:"dht_nodes"`
	DlInfoData           int64  `json:"dl_info_data"`
	DlInfoSpeed          int64  `json:"dl_info_speed"`
	DlRateLimit          int64  `json:"dl_rate_limit"`
	FreeSpaceOnDisk      int64  `json:"free_space_on_disk"`
	GlobalRatio          string `json:"global_ratio"`
	QueuedIoJobs         int64  `json:"queued_io_jobs"`
	Queueing             bool   `json:"queueing"`
	ReadCacheHits        string `json:"read_cache_hits"`
	ReadCacheOverload    string `json:"read_cache_overload"`
	RefreshInterval      int64  `json:"refresh_interval"`
	TotalBuffersSize     int64  `json:"total_buffers_size"`
	TotalPeerConnections int64  `json:"total_peer_connections"`
	TotalQueuedSize      int64  `json:"total_queued_size"`
	TotalWastedSession   int64  `json:"total_wasted_session"`
	UpInfoData           int64  `json:"up_info_data"`
	UpInfoSpeed          int64  `json:"up_info_speed"`
	UpRateLimit          int64  `json:"up_rate_limit"`
	UseAltSpeedLimits    bool   `json:"use_alt_speed_limits"`
	WriteCacheOverload   string `json:"write_cache_overload"`
}

// Log
type Log struct {
	ID        int64  `json:"id"`
	Message   string `json:"message"`
	Timestamp int64  `json:"timestamp"`
	Type      int64  `json:"type"`
}

// PeerLog
type PeerLog struct {
	ID        int64  `json:"id"`
	IP        string `json:"ip"`
	Blocked   bool   `json:"blocked"`
	Timestamp int64  `json:"timestamp"`
	Reason    string `json:"reason"`
}

type BuildInfo struct {
	Qt         string `json:"qt"`         // QT version
	Libtorrent string `json:"libtorrent"` // libtorrent version
	Boost      string `json:"boost"`      // Boost version
	Openssl    string `json:"openssl"`    // OpenSSL version
	Bitness    int    `json:"bitness"`    // Application bitness (e.g.64-bit)
}

type Cookie struct {
	Name           string `json:"name"`           // Cookie name
	Domain         string `json:"domain"`         // Cookie domain
	Path           string `json:"path"`           // Cookie path
	Value          string `json:"value"`          // Cookie value
	ExpirationDate int64  `json:"expirationDate"` // Seconds since epoch
}

// PieceState represents download state of torrent pieces.
type PieceState int

const (
	PieceStateNotDownloadYet    = 0
	PieceStateNowDownloading    = 1
	PieceStateAlreadyDownloaded = 2
)

// silence unused variable warnings
var _ = PieceStateNotDownloadYet
var _ = PieceStateNowDownloading
var _ = PieceStateAlreadyDownloaded

type WebSeed struct {
	URL string `json:"url"`
}
</file>

<file path="methods.go">
package qbittorrent

import (
	"context"
	"encoding/json"
	"io"
	"net/http"
	"net/http/httputil"
	"strconv"
	"strings"
	"time"

	"github.com/autobrr/go-qbittorrent/errors"

	"github.com/Masterminds/semver"
)

// Login https://github.com/qbittorrent/qBittorrent/wiki/WebUI-API-(qBittorrent-4.1)#authentication
func (c *Client) Login() error {
	return c.LoginCtx(context.Background())
}

func (c *Client) LoginCtx(ctx context.Context) error {
	if c.cfg.Username == "" && c.cfg.Password == "" {
		return nil
	}

	opts := map[string]string{
		"username": c.cfg.Username,
		"password": c.cfg.Password,
	}

	resp, err := c.postBasicCtx(ctx, "auth/login", opts)
	if err != nil {
		return errors.Wrap(err, "login error")
	}

	defer resp.Body.Close()

	switch resp.StatusCode {
	case http.StatusForbidden:
		return ErrIPBanned
	case http.StatusOK:
		break
	default:
		return errors.Wrap(ErrUnexpectedStatus, "login error; status code: %d", resp.StatusCode)
	}

	bodyBytes, err := io.ReadAll(resp.Body)
	if err != nil {
		return err
	}
	bodyString := string(bodyBytes)

	// read output
	if bodyString == "Fails." {
		return ErrBadCredentials
	}

	// good response == "Ok."

	// place cookies in jar for future requests
	if cookies := resp.Cookies(); len(cookies) > 0 {
		c.setCookies(cookies)
	} else if bodyString != "Ok." {
		return ErrBadCredentials
	}

	c.log.Printf("logged into client: %v", c.cfg.Host)

	return nil
}

// GetBuildInfo get qBittorrent build information.
func (c *Client) GetBuildInfo() (BuildInfo, error) {
	return c.GetBuildInfoCtx(context.Background())
}

// GetBuildInfoCtx get qBittorrent build information.
func (c *Client) GetBuildInfoCtx(ctx context.Context) (BuildInfo, error) {
	var bi BuildInfo
	resp, err := c.getCtx(ctx, "app/buildInfo", nil)
	if err != nil {
		return bi, errors.Wrap(err, "could not get app build info")
	}

	// prevent annoying unhandled error warning
	defer func(Body io.ReadCloser) {
		_ = Body.Close()
	}(resp.Body)

	if err = json.NewDecoder(resp.Body).Decode(&bi); err != nil {
		return bi, errors.Wrap(err, "could not unmarshal body")
	}

	return bi, nil
}

// Shutdown  Shuts down the qBittorrent client
func (c *Client) Shutdown() error {
	return c.ShutdownCtx(context.Background())
}

func (c *Client) ShutdownCtx(ctx context.Context) error {
	resp, err := c.postCtx(ctx, "app/shutdown", nil)
	if err != nil {
		return errors.Wrap(err, "could not trigger shutdown")
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not trigger shutdown; status code: %d", resp.StatusCode)
	}

	return nil
}

func (c *Client) setApiVersion() error {
	versionString, err := c.GetWebAPIVersionCtx(context.Background())
	if err != nil {
		return errors.Wrap(err, "could not get webapi version")
	}

	c.log.Printf("webapi version: %v", versionString)

	ver, err := semver.NewVersion(versionString)
	if err != nil {
		return errors.Wrap(err, "could not parse webapi version")
	}

	c.version = ver

	return nil
}

func (c *Client) getApiVersion() (*semver.Version, error) {
	if c.version == nil || (c.version.Major() == 0 && c.version.Minor() == 0 && c.version.Patch() == 0) {
		err := c.setApiVersion()
		if err != nil {
			return nil, err
		}
	}

	return c.version, nil
}

func (c *Client) GetAppPreferences() (AppPreferences, error) {
	return c.GetAppPreferencesCtx(context.Background())
}

func (c *Client) GetAppPreferencesCtx(ctx context.Context) (AppPreferences, error) {
	var app AppPreferences
	resp, err := c.getCtx(ctx, "app/preferences", nil)
	if err != nil {
		return app, errors.Wrap(err, "could not get app preferences")
	}

	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return app, errors.Wrap(err, "could not read body")
	}

	if err := json.Unmarshal(body, &app); err != nil {
		return app, errors.Wrap(err, "could not unmarshal body")
	}

	return app, nil
}

func (c *Client) SetPreferences(prefs map[string]interface{}) error {
	return c.SetPreferencesCtx(context.Background(), prefs)
}

func (c *Client) SetPreferencesCtx(ctx context.Context, prefs map[string]interface{}) error {
	prefsJSON, err := json.Marshal(prefs)
	if err != nil {
		return errors.Wrap(err, "could not marshal preferences")
	}

	data := map[string]string{
		"json": string(prefsJSON),
	}

	resp, err := c.postCtx(ctx, "app/setPreferences", data)
	if err != nil {
		return errors.Wrap(err, "could not set preferences")
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not set preferences; status code: %d", resp.StatusCode)
	}

	return nil
}

// GetDefaultSavePath get default save path.
// e.g. C:/Users/Dayman/Downloads
func (c *Client) GetDefaultSavePath() (string, error) {
	return c.GetDefaultSavePathCtx(context.Background())
}

// GetDefaultSavePathCtx get default save path.
// e.g. C:/Users/Dayman/Downloads
func (c *Client) GetDefaultSavePathCtx(ctx context.Context) (string, error) {
	resp, err := c.getCtx(ctx, "app/defaultSavePath", nil)
	if err != nil {
		return "", errors.Wrap(err, "could not get default save path")
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return "", errors.Wrap(ErrUnexpectedStatus, "could not get default save path; status code: %d", resp.StatusCode)
	}

	respData, err := io.ReadAll(resp.Body)
	if err != nil {
		return "", errors.Wrap(err, "could not read body")
	}

	return string(respData), nil
}

func (c *Client) GetTorrents(o TorrentFilterOptions) ([]Torrent, error) {
	return c.GetTorrentsCtx(context.Background(), o)
}

func (c *Client) GetTorrentsCtx(ctx context.Context, o TorrentFilterOptions) ([]Torrent, error) {
	opts := map[string]string{}

	if o.Reverse {
		opts["reverse"] = strconv.FormatBool(o.Reverse)
	}

	if o.Limit > 0 {
		opts["limit"] = strconv.Itoa(o.Limit)
	}

	if o.Offset > 0 {
		opts["offset"] = strconv.Itoa(o.Offset)
	}

	if o.Sort != "" {
		opts["sort"] = o.Sort
	}

	if o.Filter != "" {
		opts["filter"] = string(o.Filter)
	}

	if o.Category != "" {
		opts["category"] = o.Category
	}

	if o.Tag != "" {
		opts["tag"] = o.Tag
	}

	if len(o.Hashes) > 0 {
		opts["hashes"] = strings.Join(o.Hashes, "|")
	}

	// qbit v5.1+
	if o.IncludeTrackers {
		opts["includeTrackers"] = strconv.FormatBool(o.IncludeTrackers)
	}

	resp, err := c.getCtx(ctx, "torrents/info", opts)
	if err != nil {
		return nil, errors.Wrap(err, "get torrents error")
	}

	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, errors.Wrap(err, "could not read body")
	}

	var torrents []Torrent
	if err := json.Unmarshal(body, &torrents); err != nil {
		return nil, errors.Wrap(err, "could not unmarshal body")
	}

	return torrents, nil
}

func (c *Client) GetTorrentsActiveDownloads() ([]Torrent, error) {
	return c.GetTorrentsActiveDownloadsCtx(context.Background())
}

func (c *Client) GetTorrentsActiveDownloadsCtx(ctx context.Context) ([]Torrent, error) {
	torrents, err := c.GetTorrentsCtx(ctx, TorrentFilterOptions{Filter: TorrentFilterDownloading})
	if err != nil {
		return nil, err
	}

	res := make([]Torrent, 0)
	for _, torrent := range torrents {
		// qbit counts paused torrents as downloading as well by default
		// so only add torrents with state downloading, and not pausedDl, stalledDl etc
		if torrent.State == TorrentStateDownloading || torrent.State == TorrentStateStalledDl {
			res = append(res, torrent)
		}
	}

	return res, nil
}

func (c *Client) GetTorrentProperties(hash string) (TorrentProperties, error) {
	return c.GetTorrentPropertiesCtx(context.Background(), hash)
}

func (c *Client) GetTorrentPropertiesCtx(ctx context.Context, hash string) (TorrentProperties, error) {
	opts := map[string]string{
		"hash": hash,
	}

	var prop TorrentProperties
	resp, err := c.getCtx(ctx, "torrents/properties", opts)
	if err != nil {
		return prop, errors.Wrap(err, "could not get app preferences")
	}

	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return prop, errors.Wrap(err, "could not read body")
	}

	if err := json.Unmarshal(body, &prop); err != nil {
		return prop, errors.Wrap(err, "could not unmarshal body")
	}

	return prop, nil
}

func (c *Client) GetTorrentsRaw() (string, error) {
	return c.GetTorrentsRawCtx(context.Background())
}

func (c *Client) GetTorrentsRawCtx(ctx context.Context) (string, error) {
	resp, err := c.getCtx(ctx, "torrents/info", nil)
	if err != nil {
		return "", errors.Wrap(err, "could not get torrents raw")
	}

	defer resp.Body.Close()

	data, err := io.ReadAll(resp.Body)
	if err != nil {
		return "", errors.Wrap(err, "could not get read body torrents raw")
	}

	return string(data), nil
}

func (c *Client) GetTorrentTrackers(hash string) ([]TorrentTracker, error) {
	return c.GetTorrentTrackersCtx(context.Background(), hash)
}

func (c *Client) GetTorrentTrackersCtx(ctx context.Context, hash string) ([]TorrentTracker, error) {
	opts := map[string]string{
		"hash": hash,
	}

	resp, err := c.getCtx(ctx, "torrents/trackers", opts)
	if err != nil {
		return nil, errors.Wrap(err, "could not get torrent trackers for hash: %v", hash)
	}

	defer resp.Body.Close()

	dump, err := httputil.DumpResponse(resp, true)
	if err != nil {
		// c.log.Printf("get torrent trackers error dump response: %v\n", string(dump))
		return nil, errors.Wrap(err, "could not dump response for hash: %v", hash)
	}

	c.log.Printf("get torrent trackers response dump: %q", dump)

	if resp.StatusCode == http.StatusNotFound {
		return nil, nil
	} else if resp.StatusCode == http.StatusForbidden {
		return nil, nil
	}

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, errors.Wrap(err, "could not read body")
	}

	c.log.Printf("get torrent trackers body: %v\n", string(body))

	var trackers []TorrentTracker
	if err := json.Unmarshal(body, &trackers); err != nil {
		return nil, errors.Wrap(err, "could not unmarshal body")
	}

	return trackers, nil
}

func (c *Client) AddTorrentFromMemory(buf []byte, options map[string]string) error {
	return c.AddTorrentFromMemoryCtx(context.Background(), buf, options)
}

func (c *Client) AddTorrentFromMemoryCtx(ctx context.Context, buf []byte, options map[string]string) error {

	res, err := c.postMemoryCtx(ctx, "torrents/add", buf, options)
	if err != nil {
		return errors.Wrap(err, "could not add torrent")
	}

	defer res.Body.Close()

	if res.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not add torrent; status code: %d", res.StatusCode)
	}

	return nil
}

// AddTorrentFromFile add new torrent from torrent file
func (c *Client) AddTorrentFromFile(filePath string, options map[string]string) error {
	return c.AddTorrentFromFileCtx(context.Background(), filePath, options)
}

func (c *Client) AddTorrentFromFileCtx(ctx context.Context, filePath string, options map[string]string) error {

	res, err := c.postFileCtx(ctx, "torrents/add", filePath, options)
	if err != nil {
		return errors.Wrap(err, "could not add torrent; filePath: %v", filePath)
	}

	defer res.Body.Close()

	if res.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not add torrent; filePath: %v | status code: %d", filePath, res.StatusCode)
	}

	return nil
}

// AddTorrentFromUrl add new torrent from torrent file
func (c *Client) AddTorrentFromUrl(url string, options map[string]string) error {
	return c.AddTorrentFromUrlCtx(context.Background(), url, options)
}

func (c *Client) AddTorrentFromUrlCtx(ctx context.Context, url string, options map[string]string) error {
	if url == "" {
		return ErrNoTorrentURLProvided
	}

	options["urls"] = url

	res, err := c.postCtx(ctx, "torrents/add", options)
	if err != nil {
		return errors.Wrap(err, "could not add torrent; url: %v", url)
	}

	defer res.Body.Close()

	if res.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not add torrent: url: %v | status code: %d", url, res.StatusCode)
	}

	return nil
}

func (c *Client) DeleteTorrents(hashes []string, deleteFiles bool) error {
	return c.DeleteTorrentsCtx(context.Background(), hashes, deleteFiles)
}

func (c *Client) DeleteTorrentsCtx(ctx context.Context, hashes []string, deleteFiles bool) error {
	// Add hashes together with | separator
	hv := strings.Join(hashes, "|")

	opts := map[string]string{
		"hashes":      hv,
		"deleteFiles": strconv.FormatBool(deleteFiles),
	}

	resp, err := c.postCtx(ctx, "torrents/delete", opts)
	if err != nil {
		return errors.Wrap(err, "could not delete torrents; hashes: %v", hashes)
	}

	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not delete torrents; hashes: %v | status code: %d", hashes, resp.StatusCode)
	}

	return nil
}

func (c *Client) ReAnnounceTorrents(hashes []string) error {
	return c.ReAnnounceTorrentsCtx(context.Background(), hashes)
}

func (c *Client) ReAnnounceTorrentsCtx(ctx context.Context, hashes []string) error {
	// Add hashes together with | separator
	hv := strings.Join(hashes, "|")
	opts := map[string]string{
		"hashes": hv,
	}

	resp, err := c.postCtx(ctx, "torrents/reannounce", opts)
	if err != nil {
		return errors.Wrap(err, "could not re-announce torrents; hashes: %v", hashes)
	}

	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not re-announce torrents; hashes: %v | status code: %d", hashes, resp.StatusCode)
	}

	return nil
}

func (c *Client) GetTransferInfo() (*TransferInfo, error) {
	return c.GetTransferInfoCtx(context.Background())
}

func (c *Client) GetTransferInfoCtx(ctx context.Context) (*TransferInfo, error) {
	resp, err := c.getCtx(ctx, "transfer/info", nil)
	if err != nil {
		return nil, errors.Wrap(err, "could not get transfer info")
	}

	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, errors.Wrap(err, "could not read body")
	}

	var info TransferInfo
	if err := json.Unmarshal(body, &info); err != nil {
		return nil, errors.Wrap(err, "could not unmarshal body")
	}

	return &info, nil
}

// BanPeers bans peers.
// Each peer is a colon-separated host:port pair
func (c *Client) BanPeers(peers []string) error {
	return c.BanPeersCtx(context.Background(), peers)
}

// BanPeersCtx bans peers.
// Each peer is a colon-separated host:port pair
func (c *Client) BanPeersCtx(ctx context.Context, peers []string) error {
	data := map[string]string{
		"peers": strings.Join(peers, "|"),
	}

	resp, err := c.postCtx(ctx, "transfer/banPeers", data)
	if err != nil {
		return errors.Wrap(err, "could not ban peers; peers: %v", peers)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not ban peers; peers: %v | status code: %d", peers, resp.StatusCode)
	}

	return nil
}

// SyncMainDataCtx Sync API implements requests for obtaining changes since the last request.
// Response ID. If not provided, rid=0 will be assumed. If the given rid is different from the one of last server reply, full_update will be true (see the server reply details for more info)
func (c *Client) SyncMainDataCtx(ctx context.Context, rid int64) (*MainData, error) {
	opts := map[string]string{
		"rid": strconv.FormatInt(rid, 10),
	}

	resp, err := c.getCtx(ctx, "/sync/maindata", opts)
	if err != nil {
		return nil, errors.Wrap(err, "could not get main data")
	}

	defer resp.Body.Close()

	var info MainData
	if err := json.NewDecoder(resp.Body).Decode(&info); err != nil {
		return nil, errors.Wrap(err, "could not unmarshal body")
	}

	return &info, nil

}

func (c *Client) Pause(hashes []string) error {
	return c.PauseCtx(context.Background(), hashes)
}

func (c *Client) Stop(hashes []string) error {
	return c.PauseCtx(context.Background(), hashes)
}

func (c *Client) StopCtx(ctx context.Context, hashes []string) error {
	return c.PauseCtx(ctx, hashes)
}

func (c *Client) PauseCtx(ctx context.Context, hashes []string) error {
	// Add hashes together with | separator
	hv := strings.Join(hashes, "|")
	opts := map[string]string{
		"hashes": hv,
	}

	endpoint := "torrents/stop"

	// Qbt WebAPI 2.11 changed pause with stop
	version, err := c.getApiVersion()
	if err != nil {
		return errors.Wrap(err, "could not get api version")
	}

	if version.Major() == 2 && version.Minor() < 11 {
		endpoint = "torrents/pause"
	}

	resp, err := c.postCtx(ctx, endpoint, opts)
	if err != nil {
		return errors.Wrap(err, "could not pause torrents; hashes: %v", hashes)
	}

	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not pause torrents; hashes: %v | status code: %d", hashes, resp.StatusCode)
	}

	return nil
}

func (c *Client) Resume(hashes []string) error {
	return c.ResumeCtx(context.Background(), hashes)
}

func (c *Client) Start(hashes []string) error {
	return c.ResumeCtx(context.Background(), hashes)
}

func (c *Client) StartCtx(ctx context.Context, hashes []string) error {
	return c.ResumeCtx(ctx, hashes)
}

func (c *Client) ResumeCtx(ctx context.Context, hashes []string) error {
	// Add hashes together with | separator
	hv := strings.Join(hashes, "|")
	opts := map[string]string{
		"hashes": hv,
	}

	endpoint := "torrents/start"

	// Qbt WebAPI 2.11 changed resume with start
	version, err := c.getApiVersion()

	if err != nil {
		return errors.Wrap(err, "could not get api version")
	}

	if version.Major() == 2 && version.Minor() < 11 {
		endpoint = "torrents/resume"
	}

	resp, err := c.postCtx(ctx, endpoint, opts)
	if err != nil {
		return errors.Wrap(err, "could not resume torrents; hashes: %v", hashes)
	}

	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not resume torrents; hashes: %v | status code: %d", hashes, resp.StatusCode)
	}

	return nil
}

func (c *Client) SetForceStart(hashes []string, value bool) error {
	return c.SetForceStartCtx(context.Background(), hashes, value)
}

func (c *Client) SetForceStartCtx(ctx context.Context, hashes []string, value bool) error {
	// Add hashes together with | separator
	hv := strings.Join(hashes, "|")
	opts := map[string]string{
		"hashes": hv,
		"value":  strconv.FormatBool(value),
	}

	resp, err := c.postCtx(ctx, "torrents/setForceStart", opts)
	if err != nil {
		return errors.Wrap(err, "could not set force start torrents; hashes: %v", hashes)
	}

	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not set force start torrents; hashes: %v | status code: %d", hashes, resp.StatusCode)
	}

	return nil
}

func (c *Client) Recheck(hashes []string) error {
	return c.RecheckCtx(context.Background(), hashes)
}

func (c *Client) RecheckCtx(ctx context.Context, hashes []string) error {
	// Add hashes together with | separator
	hv := strings.Join(hashes, "|")
	opts := map[string]string{
		"hashes": hv,
	}

	resp, err := c.postCtx(ctx, "torrents/recheck", opts)
	if err != nil {
		return errors.Wrap(err, "could not recheck torrents; hashes: %v", hashes)
	}

	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not recheck torrents; hashes: %v | status code: %d", hashes, resp.StatusCode)
	}

	return nil
}

func (c *Client) SetAutoManagement(hashes []string, enable bool) error {
	return c.SetAutoManagementCtx(context.Background(), hashes, enable)
}

func (c *Client) SetAutoManagementCtx(ctx context.Context, hashes []string, enable bool) error {
	// Add hashes together with | separator
	hv := strings.Join(hashes, "|")
	opts := map[string]string{
		"hashes": hv,
		"enable": strconv.FormatBool(enable),
	}

	resp, err := c.postCtx(ctx, "torrents/setAutoManagement", opts)
	if err != nil {
		return errors.Wrap(err, "could not set auto management; hashes: %v", hashes)
	}

	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not set auto management; hashes: %v | status code: %d", hashes, resp.StatusCode)
	}

	return nil
}

func (c *Client) SetLocation(hashes []string, location string) error {
	return c.SetLocationCtx(context.Background(), hashes, location)
}

func (c *Client) SetLocationCtx(ctx context.Context, hashes []string, location string) error {
	// Add hashes together with | separator
	hv := strings.Join(hashes, "|")
	opts := map[string]string{
		"hashes":   hv,
		"location": location,
	}

	resp, err := c.postCtx(ctx, "torrents/setLocation", opts)
	if err != nil {
		return errors.Wrap(err, "could not set location; hashes: %v | location: %s", hashes, location)
	}

	defer resp.Body.Close()

	/*
		HTTP Status Code 	Scenario
		400 	Save path is empty
		403     User does not have write access to directory
		409     Unable to create save path directory
		200 	All other scenarios
	*/
	switch sc := resp.StatusCode; sc {
	case http.StatusOK:
		return nil
	case http.StatusBadRequest:
		return errors.Wrap(ErrEmptySavePath, "save path: %s", location)
	case http.StatusForbidden:
		return ErrNoWriteAccessToPath
	case http.StatusConflict:
		return ErrCannotCreateSavePath
	default:
		return errors.Wrap(ErrUnexpectedStatus, "could not set location; hashes: %v | location: %v | status code: %d", hashes, location, resp.StatusCode)
	}
}

func (c *Client) CreateCategory(category string, path string) error {
	return c.CreateCategoryCtx(context.Background(), category, path)
}

func (c *Client) CreateCategoryCtx(ctx context.Context, category string, path string) error {
	opts := map[string]string{
		"category": category,
		"savePath": path,
	}

	resp, err := c.postCtx(ctx, "torrents/createCategory", opts)
	if err != nil {
		return errors.Wrap(err, "could not create category; category: %v", category)
	}

	defer resp.Body.Close()

	/*
		HTTP Status Code 	Scenario
		400     Category name is empty
		409 	Category name is invalid
		200 	All other scenarios
	*/
	switch resp.StatusCode {
	case http.StatusOK:
		return nil
	case http.StatusBadRequest:
		return errors.Wrap(ErrEmptyCategoryName, "category name: %s", category)
	case http.StatusConflict:
		return errors.Wrap(ErrInvalidCategoryName, "category name: %s", category)
	default:
		return errors.Wrap(ErrUnexpectedStatus, "could not create category; category: %v | status code: %d", category, resp.StatusCode)
	}
}

func (c *Client) EditCategory(category string, path string) error {
	return c.EditCategoryCtx(context.Background(), category, path)
}

func (c *Client) EditCategoryCtx(ctx context.Context, category string, path string) error {
	opts := map[string]string{
		"category": category,
		"savePath": path,
	}

	resp, err := c.postCtx(ctx, "torrents/editCategory", opts)
	if err != nil {
		return errors.Wrap(err, "could not edit category; category: %v", category)
	}

	defer resp.Body.Close()

	/*
		HTTP Status Code 	Scenario
		400     Category name is empty
		409 	Category editing failed
		200 	All other scenarios
	*/
	switch resp.StatusCode {
	case http.StatusOK:
		return nil
	case http.StatusBadRequest:
		return errors.Wrap(ErrEmptyCategoryName, "category name: %s", category)
	case http.StatusConflict:
		return ErrCategoryEditingFailed
	default:
		return errors.Wrap(ErrUnexpectedStatus, "could not edit category; category %v | status code: %d", category, resp.StatusCode)
	}
}

func (c *Client) RemoveCategories(categories []string) error {
	return c.RemoveCategoriesCtx(context.Background(), categories)
}

func (c *Client) RemoveCategoriesCtx(ctx context.Context, categories []string) error {
	opts := map[string]string{
		"categories": strings.Join(categories, "\n"),
	}

	resp, err := c.postCtx(ctx, "torrents/removeCategories", opts)
	if err != nil {
		return errors.Wrap(err, "could not remove categories; categories: %v", opts["categories"])
	}

	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not remove categories; categories: %v | status code: %d", opts["categories"], resp.StatusCode)
	}

	return nil
}

func (c *Client) SetCategory(hashes []string, category string) error {
	return c.SetCategoryCtx(context.Background(), hashes, category)
}

func (c *Client) SetCategoryCtx(ctx context.Context, hashes []string, category string) error {
	// Add hashes together with | separator
	hv := strings.Join(hashes, "|")
	opts := map[string]string{
		"hashes":   hv,
		"category": category,
	}

	resp, err := c.postCtx(ctx, "torrents/setCategory", opts)
	if err != nil {
		return errors.Wrap(err, "could not set category; hashes: %v | category: %s", hashes, category)
	}

	defer resp.Body.Close()

	/*
		HTTP Status Code 	Scenario
		409 	Category name does not exist
		200 	All other scenarios
	*/
	switch resp.StatusCode {
	case http.StatusOK:
		return nil
	case http.StatusConflict:
		return errors.Wrap(ErrCategoryDoesNotExist, "category name: %s", category)
	default:
		return errors.Wrap(ErrUnexpectedStatus, "could not set category; hashes: %v | cateogry: %s | status code: %d", hashes, category, resp.StatusCode)
	}
}

func (c *Client) GetCategories() (map[string]Category, error) {
	return c.GetCategoriesCtx(context.Background())
}

func (c *Client) GetCategoriesCtx(ctx context.Context) (map[string]Category, error) {
	resp, err := c.getCtx(ctx, "torrents/categories", nil)
	if err != nil {
		return nil, errors.Wrap(err, "could not get files info")
	}

	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, errors.Wrap(err, "could not read body")
	}

	m := make(map[string]Category)
	if err := json.Unmarshal(body, &m); err != nil {
		return nil, errors.Wrap(err, "could not unmarshal body")
	}

	return m, nil
}

func (c *Client) GetFilesInformation(hash string) (*TorrentFiles, error) {
	return c.GetFilesInformationCtx(context.Background(), hash)
}

func (c *Client) GetFilesInformationCtx(ctx context.Context, hash string) (*TorrentFiles, error) {
	opts := map[string]string{
		"hash": hash,
	}

	resp, err := c.getCtx(ctx, "torrents/files", opts)
	if err != nil {
		return nil, errors.Wrap(err, "could not get files info")
	}

	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, errors.Wrap(err, "could not read body")
	}

	var info TorrentFiles
	if err := json.Unmarshal(body, &info); err != nil {
		return nil, errors.Wrap(err, "could not unmarshal body")
	}

	return &info, nil
}

// SetFilePriority Set file priority
func (c *Client) SetFilePriority(hash string, IDs string, priority int) error {
	return c.SetFilePriorityCtx(context.Background(), hash, IDs, priority)
}

// SetFilePriorityCtx Set file priority
func (c *Client) SetFilePriorityCtx(ctx context.Context, hash string, IDs string, priority int) error {
	opts := map[string]string{
		"hash":     hash,
		"id":       IDs,
		"priority": strconv.Itoa(priority),
	}

	resp, err := c.postCtx(ctx, "torrents/filePrio", opts)
	if err != nil {
		return errors.Wrap(err, "could not set file priority; hash: %s | priority: %d", hash, priority)
	}

	defer resp.Body.Close()

	/*
		HTTP Status Code 	Scenario
		400		Priority is invalid
		400 	At least one file id is not a valid integer
		404 	Torrent hash was not found
		409 	Torrent metadata hasn't downloaded yet
		409 	At least one file id was not found
		200 	All other scenarios
	*/
	switch resp.StatusCode {
	case http.StatusBadRequest:
		return ErrInvalidPriority
	case http.StatusNotFound:
		return errors.Wrap(ErrTorrentNotFound, "hash: %s", hash)
	case http.StatusConflict:
		return ErrTorrentMetdataNotDownloadedYet
	case http.StatusOK:
		return nil
	default:
		return errors.Wrap(ErrUnexpectedStatus, "could not set file priority; hash: %v | priority: %d | status code: %d", hash, priority, resp.StatusCode)
	}
}

func (c *Client) ExportTorrent(hash string) ([]byte, error) {
	return c.ExportTorrentCtx(context.Background(), hash)
}

func (c *Client) ExportTorrentCtx(ctx context.Context, hash string) ([]byte, error) {
	opts := map[string]string{
		"hash": hash,
	}

	resp, err := c.getCtx(ctx, "torrents/export", opts)
	if err != nil {
		return nil, errors.Wrap(err, "could not get export")
	}

	defer resp.Body.Close()

	return io.ReadAll(resp.Body)
}

func (c *Client) RenameFile(hash, oldPath, newPath string) error {
	return c.RenameFileCtx(context.Background(), hash, oldPath, newPath)
}

func (c *Client) RenameFileCtx(ctx context.Context, hash, oldPath, newPath string) error {
	opts := map[string]string{
		"hash":    hash,
		"oldPath": oldPath,
		"newPath": newPath,
	}

	resp, err := c.postCtx(ctx, "torrents/renameFile", opts)
	if err != nil {
		return errors.Wrap(err, "could not rename file; hash: %v | oldPath: %v | newPath: %v", hash, oldPath, newPath)
	}

	defer resp.Body.Close()

	/*
		HTTP Status Code 	Scenario
		400 	Missing newPath parameter
		409 	Invalid newPath or oldPath, or newPath already in use
		200 	All other scenarios
	*/
	switch resp.StatusCode {
	case http.StatusBadRequest:
		return errors.Wrap(ErrMissingNewPathParameter, "newPath: %v", newPath)
	case http.StatusConflict:
		return errors.Wrap(ErrInvalidPathParameter, "oldPath: %v | newPath: %v", oldPath, newPath)
	case http.StatusOK:
		return nil
	default:
		return errors.Wrap(ErrUnexpectedStatus, "could not rename file; hash %v | oldPath: %v | newPath: %v | status code: %d", hash, oldPath, newPath, resp.StatusCode)
	}
}

// RenameFolder Rename folder in torrent
func (c *Client) RenameFolder(hash, oldPath, newPath string) error {
	return c.RenameFolderCtx(context.Background(), hash, oldPath, newPath)
}

// RenameFolderCtx Rename folder in torrent
func (c *Client) RenameFolderCtx(ctx context.Context, hash, oldPath, newPath string) error {
	opts := map[string]string{
		"hash":    hash,
		"oldPath": oldPath,
		"newPath": newPath,
	}

	resp, err := c.postCtx(ctx, "torrents/renameFolder", opts)
	if err != nil {
		return errors.Wrap(err, "could not rename folder; hash: %v | oldPath: %v | newPath: %v", hash, oldPath, newPath)
	}

	defer func(Body io.ReadCloser) {
		_ = Body.Close()
	}(resp.Body)

	switch resp.StatusCode {
	case http.StatusBadRequest:
		return errors.Wrap(ErrMissingNewPathParameter, "newPath: %v", newPath)
	case http.StatusConflict:
		return errors.Wrap(ErrInvalidPathParameter, "oldPath: %v | newPath: %v", oldPath, newPath)
	case http.StatusOK:
		return nil
	default:
		return errors.Wrap(ErrUnexpectedStatus, "could not rename folder; hash %v | oldPath: %v | newPath: %v | status code: %d", hash, oldPath, newPath, resp.StatusCode)
	}
}

// SetTorrentName set name for torrent specified by hash
func (c *Client) SetTorrentName(hash string, name string) error {
	return c.SetTorrentNameCtx(context.Background(), hash, name)
}

// SetTorrentNameCtx set name for torrent specified by hash
func (c *Client) SetTorrentNameCtx(ctx context.Context, hash string, name string) error {
	opts := map[string]string{
		"hash": hash,
		"name": name,
	}

	resp, err := c.postCtx(ctx, "torrents/rename", opts)
	if err != nil {
		return errors.Wrap(err, "could not rename torrent; hash: %v | name: %v", hash, name)
	}

	defer resp.Body.Close()

	switch sc := resp.StatusCode; sc {
	case http.StatusOK:
		return nil
	case http.StatusNotFound:
		return errors.Wrap(ErrInvalidTorrentHash, "torrent hash: %v", hash)
	case http.StatusConflict:
		return errors.Wrap(ErrEmptyTorrentName, "torrent name: %v", name)
	default:
		return errors.Wrap(ErrUnexpectedStatus, "could not rename torrent; hash: %v | name: %s |status code: %d", hash, name, resp.StatusCode)
	}
}

func (c *Client) GetTags() ([]string, error) {
	return c.GetTagsCtx(context.Background())
}

func (c *Client) GetTagsCtx(ctx context.Context) ([]string, error) {
	resp, err := c.getCtx(ctx, "torrents/tags", nil)
	if err != nil {
		return nil, errors.Wrap(err, "could not get tags")
	}

	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, errors.Wrap(err, "could not read body")
	}

	m := make([]string, 0)
	if err := json.Unmarshal(body, &m); err != nil {
		return nil, errors.Wrap(err, "could not unmarshal body")
	}

	return m, nil
}

func (c *Client) CreateTags(tags []string) error {
	return c.CreateTagsCtx(context.Background(), tags)
}

func (c *Client) CreateTagsCtx(ctx context.Context, tags []string) error {
	t := strings.Join(tags, ",")

	opts := map[string]string{
		"tags": t,
	}

	resp, err := c.postCtx(ctx, "torrents/createTags", opts)
	if err != nil {
		return errors.Wrap(err, "could not create tags; tags: %v", t)
	}

	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not create tags; tags: %v | status code: %d", t, resp.StatusCode)
	}

	return nil
}

func (c *Client) AddTags(hashes []string, tags string) error {
	return c.AddTagsCtx(context.Background(), hashes, tags)
}

func (c *Client) AddTagsCtx(ctx context.Context, hashes []string, tags string) error {
	// Add hashes together with | separator
	hv := strings.Join(hashes, "|")
	opts := map[string]string{
		"hashes": hv,
		"tags":   tags,
	}

	resp, err := c.postCtx(ctx, "torrents/addTags", opts)
	if err != nil {
		return errors.Wrap(err, "could not add tags; hashes: %v |tags: %v", hashes, tags)
	}

	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not add tags; hashes: %v | tags: %v | status code: %d", hashes, tags, resp.StatusCode)
	}

	return nil
}

// SetTags is a new method in qBittorrent 5.1 WebAPI 2.11.4 that allows for upserting tags in one go, instead of having to remove and add tags in different calls.
// For client instances with a lot of torrents, this will benefit a lot.
// It checks for the required min version, and if it's less than the required version, it will error, and then the caller can handle it how they want.
func (c *Client) SetTags(ctx context.Context, hashes []string, tags string) error {
	if ok, err := c.RequiresMinVersion(semver.MustParse("2.11.4")); !ok {
		return errors.Wrap(err, "SetTags requires qBittorrent 5.1 and WebAPI >= 2.11.4")
	}

	// Add hashes together with | separator
	hv := strings.Join(hashes, "|")
	opts := map[string]string{
		"hashes": hv,
		"tags":   tags,
	}

	resp, err := c.postCtx(ctx, "torrents/setTags", opts)
	if err != nil {
		return errors.Wrap(err, "could not set tags; hashes: %v", hashes)
	}

	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not set tags; hashes: %v | status code: %d", hashes, resp.StatusCode)
	}

	return nil
}

// DeleteTags delete tags from qBittorrent
func (c *Client) DeleteTags(tags []string) error {
	return c.DeleteTagsCtx(context.Background(), tags)
}

// DeleteTagsCtx delete tags from qBittorrent
func (c *Client) DeleteTagsCtx(ctx context.Context, tags []string) error {
	t := strings.Join(tags, ",")

	opts := map[string]string{
		"tags": t,
	}

	resp, err := c.postCtx(ctx, "torrents/deleteTags", opts)
	if err != nil {
		return errors.Wrap(err, "could not delete tags; tags: %s", t)
	}

	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not delete tags; tags: %s | status code: %d", t, resp.StatusCode)
	}

	return nil
}

// RemoveTags remove tags from torrents specified by hashes
func (c *Client) RemoveTags(hashes []string, tags string) error {
	return c.RemoveTagsCtx(context.Background(), hashes, tags)
}

// RemoveTagsCtx remove tags from torrents specified by hashes
func (c *Client) RemoveTagsCtx(ctx context.Context, hashes []string, tags string) error {
	// Add hashes together with | separator
	hv := strings.Join(hashes, "|")

	opts := map[string]string{
		"hashes": hv,
	}

	if len(tags) != 0 {
		opts["tags"] = tags
	}

	resp, err := c.postCtx(ctx, "torrents/removeTags", opts)
	if err != nil {
		return errors.Wrap(err, "could not remove tags; hashes: %v | tags %s", hashes, tags)
	}

	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not remove tags; hashes: %v | tags: %s | status code: %d", hashes, tags, resp.StatusCode)
	}

	return nil
}

// RemoveTracker remove trackers of torrent
func (c *Client) RemoveTrackers(hash string, urls string) error {
	return c.RemoveTrackersCtx(context.Background(), hash, urls)
}

// RemoveTrackersCtx remove trackers of torrent
func (c *Client) RemoveTrackersCtx(ctx context.Context, hash string, urls string) error {
	opts := map[string]string{
		"hash": hash,
		"urls": urls,
	}

	resp, err := c.postCtx(ctx, "torrents/removeTrackers", opts)
	if err != nil {
		return errors.Wrap(err, "could not remove trackers; hash: %s | urls: %s", hash, urls)
	}

	defer resp.Body.Close()

	/*
		HTTP Status Code 	Scenario
		404 	Torrent hash was not found
		409 	All URLs were not found
		200 	All other scenarios
	*/
	switch resp.StatusCode {
	case http.StatusNotFound:
		return errors.Wrap(ErrTorrentNotFound, "torrent hash: %v", hash)
	case http.StatusConflict:
		return errors.Wrap(ErrAllURLsNotFound, "urls: %v", urls)
	case http.StatusOK:
		return nil
	default:
		return errors.Wrap(ErrUnexpectedStatus, "could not remove trackers; hash: %s | urls: %s | status code: %d", hash, urls, resp.StatusCode)
	}
}

// EditTracker edit tracker of torrent
func (c *Client) EditTracker(hash string, old, new string) error {
	return c.EditTrackerCtx(context.Background(), hash, old, new)
}

// EditTrackerCtx edit tracker of torrent
func (c *Client) EditTrackerCtx(ctx context.Context, hash string, old, new string) error {
	opts := map[string]string{
		"hash":    hash,
		"origUrl": old,
		"newUrl":  new,
	}

	resp, err := c.postCtx(ctx, "torrents/editTracker", opts)
	if err != nil {
		return errors.Wrap(err, "could not edit tracker; hash: %s | old: %s | new: %s", hash, old, new)
	}

	defer resp.Body.Close()

	/*
		HTTP Status Code 	Scenario
		400 	newUrl is not a valid URL
		404 	Torrent hash was not found
		409 	newUrl already exists for the torrent
		409 	origUrl was not found
		200 	All other scenarios
	*/
	switch resp.StatusCode {
	case http.StatusBadRequest:
		return errors.Wrap(ErrInvalidURL, "new url: %v", new)
	case http.StatusNotFound:
		return errors.Wrap(ErrTorrentNotFound, "torrent hash: %v", hash)
	case http.StatusConflict:
		return nil
	case http.StatusOK:
		return nil
	default:
		return errors.Wrap(ErrUnexpectedStatus, "could not edit tracker; hash: %s | old: %s | new: %s | status code: %d", hash, old, new, resp.StatusCode)
	}
}

// AddTrackers add trackers of torrent
func (c *Client) AddTrackers(hash string, urls string) error {
	return c.AddTrackersCtx(context.Background(), hash, urls)
}

// AddTrackersCtx add trackers of torrent
func (c *Client) AddTrackersCtx(ctx context.Context, hash string, urls string) error {
	opts := map[string]string{
		"hash": hash,
		"urls": urls,
	}

	resp, err := c.postCtx(ctx, "torrents/addTrackers", opts)
	if err != nil {
		return errors.Wrap(err, "could not add trackers; hash: %s | urls: %s", hash, urls)
	}

	defer resp.Body.Close()

	/*
		HTTP Status Code 	Scenario
		404 	Torrent hash was not found
		200 	All other scenarios
	*/
	switch resp.StatusCode {
	case http.StatusNotFound:
		return errors.Wrap(ErrTorrentNotFound, "torrent hash: %v", hash)
	case http.StatusOK:
		return nil
	default:
		return errors.Wrap(ErrUnexpectedStatus, "could not add trackers; hash: %s | urls: %s | status code: %d", hash, urls, resp.StatusCode)
	}
}

// SetPreferencesQueueingEnabled enable/disable torrent queueing
func (c *Client) SetPreferencesQueueingEnabled(enabled bool) error {
	return c.SetPreferences(map[string]interface{}{"queueing_enabled": enabled})
}

// SetPreferencesMaxActiveDownloads set max active downloads
func (c *Client) SetPreferencesMaxActiveDownloads(max int) error {
	return c.SetPreferences(map[string]interface{}{"max_active_downloads": max})
}

// SetPreferencesMaxActiveTorrents set max active torrents
func (c *Client) SetPreferencesMaxActiveTorrents(max int) error {
	return c.SetPreferences(map[string]interface{}{"max_active_torrents": max})
}

// SetPreferencesMaxActiveUploads set max active uploads
func (c *Client) SetPreferencesMaxActiveUploads(max int) error {
	return c.SetPreferences(map[string]interface{}{"max_active_uploads": max})
}

// SetMaxPriority set torrents to max priority specified by hashes
func (c *Client) SetMaxPriority(hashes []string) error {
	return c.SetMaxPriorityCtx(context.Background(), hashes)
}

// SetMaxPriorityCtx set torrents to max priority specified by hashes
func (c *Client) SetMaxPriorityCtx(ctx context.Context, hashes []string) error {
	// Add hashes together with | separator
	hv := strings.Join(hashes, "|")

	opts := map[string]string{
		"hashes": hv,
	}

	resp, err := c.postCtx(ctx, "torrents/topPrio", opts)
	if err != nil {
		return errors.Wrap(err, "could not set maximum priority; hashes: %v", hashes)
	}

	defer resp.Body.Close()

	if resp.StatusCode == http.StatusConflict {
		return errors.Wrap(ErrTorrentQueueingNotEnabled, "hashes: %v", hashes)
	} else if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not set maximum priority; hashes: %v | status code: %d", hashes, resp.StatusCode)
	}

	return nil
}

// SetMinPriority set torrents to min priority specified by hashes
func (c *Client) SetMinPriority(hashes []string) error {
	return c.SetMinPriorityCtx(context.Background(), hashes)
}

// SetMinPriorityCtx set torrents to min priority specified by hashes
func (c *Client) SetMinPriorityCtx(ctx context.Context, hashes []string) error {
	// Add hashes together with | separator
	hv := strings.Join(hashes, "|")

	opts := map[string]string{
		"hashes": hv,
	}

	resp, err := c.postCtx(ctx, "torrents/bottomPrio", opts)
	if err != nil {
		return errors.Wrap(err, "could not set minimum priority; hashes: %v", hashes)
	}

	defer resp.Body.Close()

	if resp.StatusCode == http.StatusConflict {
		return errors.Wrap(ErrTorrentQueueingNotEnabled, "hashes: %v", hashes)
	} else if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not set minimum priority; hashes: %v | status code: %d", hashes, resp.StatusCode)
	}

	return nil
}

// DecreasePriority decrease priority for torrents specified by hashes
func (c *Client) DecreasePriority(hashes []string) error {
	return c.DecreasePriorityCtx(context.Background(), hashes)
}

// DecreasePriorityCtx decrease priority for torrents specified by hashes
func (c *Client) DecreasePriorityCtx(ctx context.Context, hashes []string) error {
	// Add hashes together with | separator
	hv := strings.Join(hashes, "|")

	opts := map[string]string{
		"hashes": hv,
	}

	resp, err := c.postCtx(ctx, "torrents/decreasePrio", opts)
	if err != nil {
		return errors.Wrap(err, "could not decrease priority; hashes: %v", hashes)
	}

	defer resp.Body.Close()

	if resp.StatusCode == http.StatusConflict {
		return errors.Wrap(ErrTorrentQueueingNotEnabled, "hashes: %v", hashes)
	} else if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not decrease priority; hashes: %v | status code: %d", hashes, resp.StatusCode)
	}

	return nil
}

// IncreasePriority increase priority for torrents specified by hashes
func (c *Client) IncreasePriority(hashes []string) error {
	return c.IncreasePriorityCtx(context.Background(), hashes)
}

// IncreasePriorityCtx increase priority for torrents specified by hashes
func (c *Client) IncreasePriorityCtx(ctx context.Context, hashes []string) error {
	// Add hashes together with | separator
	hv := strings.Join(hashes, "|")

	opts := map[string]string{
		"hashes": hv,
	}

	resp, err := c.postCtx(ctx, "torrents/increasePrio", opts)
	if err != nil {
		return errors.Wrap(err, "could not increase torrent priority; hashes: %v", hashes)
	}

	defer resp.Body.Close()

	if resp.StatusCode == http.StatusConflict {
		return errors.Wrap(ErrTorrentQueueingNotEnabled, "hashes: %v", hashes)
	} else if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not increase priority; hashes: %v | status code: %d", hashes, resp.StatusCode)
	}

	return nil
}

// ToggleFirstLastPiecePrio toggles the priority of the first and last pieces of torrents specified by hashes
func (c *Client) ToggleFirstLastPiecePrio(hashes []string) error {
	return c.ToggleFirstLastPiecePrioCtx(context.Background(), hashes)
}

// ToggleFirstLastPiecePrioCtx toggles the priority of the first and last pieces of torrents specified by hashes
func (c *Client) ToggleFirstLastPiecePrioCtx(ctx context.Context, hashes []string) error {
	hv := strings.Join(hashes, "|")

	opts := map[string]string{
		"hashes": hv,
	}

	resp, err := c.postCtx(ctx, "torrents/toggleFirstLastPiecePrio", opts)
	if err != nil {
		return errors.Wrap(err, "could not toggle first/last piece priority; hashes: %v", hashes)
	}

	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not toggle first/last piece priority; hashes: %v | status code: %d", hashes, resp.StatusCode)
	}

	return nil
}

// ToggleAlternativeSpeedLimits toggle alternative speed limits globally
func (c *Client) ToggleAlternativeSpeedLimits() error {
	return c.ToggleAlternativeSpeedLimitsCtx(context.Background())
}

// ToggleAlternativeSpeedLimitsCtx toggle alternative speed limits globally
func (c *Client) ToggleAlternativeSpeedLimitsCtx(ctx context.Context) error {
	resp, err := c.postCtx(ctx, "transfer/toggleSpeedLimitsMode", nil)
	if err != nil {
		return errors.Wrap(err, "could not toggle alternative speed limits")
	}

	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not stoggle alternative speed limits; status code: %d", resp.StatusCode)
	}

	return nil
}

// GetAlternativeSpeedLimitsMode get alternative speed limits mode
func (c *Client) GetAlternativeSpeedLimitsMode() (bool, error) {
	return c.GetAlternativeSpeedLimitsModeCtx(context.Background())
}

// GetAlternativeSpeedLimitsModeCtx get alternative speed limits mode
func (c *Client) GetAlternativeSpeedLimitsModeCtx(ctx context.Context) (bool, error) {
	var m bool
	resp, err := c.getCtx(ctx, "transfer/speedLimitsMode", nil)
	if err != nil {
		return m, errors.Wrap(err, "could not get alternative speed limits mode")
	}

	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return m, errors.Wrap(err, "could not read body")
	}
	var d int64
	if err := json.Unmarshal(body, &d); err != nil {
		return m, errors.Wrap(err, "could not unmarshal body")
	}
	m = d == 1
	return m, nil
}

// SetGlobalDownloadLimit set download limit globally
func (c *Client) SetGlobalDownloadLimit(limit int64) error {
	return c.SetGlobalDownloadLimitCtx(context.Background(), limit)
}

// SetGlobalDownloadLimitCtx set download limit globally
func (c *Client) SetGlobalDownloadLimitCtx(ctx context.Context, limit int64) error {
	opts := map[string]string{
		"limit": strconv.FormatInt(limit, 10),
	}

	resp, err := c.postCtx(ctx, "transfer/setDownloadLimit", opts)
	if err != nil {
		return errors.Wrap(err, "could not set global download limit; limit: %d", limit)
	}

	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not set global download limit; limit: %d | status code: %d", limit, resp.StatusCode)
	}

	return nil
}

// GetGlobalDownloadLimit get global upload limit
func (c *Client) GetGlobalDownloadLimit() (int64, error) {
	return c.GetGlobalDownloadLimitCtx(context.Background())
}

// GetGlobalDownloadLimitCtx get global upload limit
func (c *Client) GetGlobalDownloadLimitCtx(ctx context.Context) (int64, error) {
	var m int64
	resp, err := c.getCtx(ctx, "transfer/downloadLimit", nil)
	if err != nil {
		return m, errors.Wrap(err, "could not get global download limit")
	}

	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return m, errors.Wrap(err, "could not read body")
	}

	if err := json.Unmarshal(body, &m); err != nil {
		return m, errors.Wrap(err, "could not unmarshal body")
	}

	return m, nil
}

// SetGlobalUploadLimit set upload limit globally
func (c *Client) SetGlobalUploadLimit(limit int64) error {
	return c.SetGlobalUploadLimitCtx(context.Background(), limit)
}

// SetGlobalUploadLimitCtx set upload limit globally
func (c *Client) SetGlobalUploadLimitCtx(ctx context.Context, limit int64) error {
	opts := map[string]string{
		"limit": strconv.FormatInt(limit, 10),
	}

	resp, err := c.postCtx(ctx, "transfer/setUploadLimit", opts)
	if err != nil {
		return errors.Wrap(err, "could not set global upload limit; limit %d", limit)
	}

	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not set global upload limit; limit %d | status code: %d", limit, resp.StatusCode)
	}

	return nil
}

// GetGlobalUploadLimit get global upload limit
func (c *Client) GetGlobalUploadLimit() (int64, error) {
	return c.GetGlobalUploadLimitCtx(context.Background())
}

// GetGlobalUploadLimitCtx get global upload limit
func (c *Client) GetGlobalUploadLimitCtx(ctx context.Context) (int64, error) {
	var m int64
	resp, err := c.getCtx(ctx, "transfer/uploadLimit", nil)
	if err != nil {
		return m, errors.Wrap(err, "could not get global upload limit")
	}

	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return m, errors.Wrap(err, "could not read body")
	}

	if err := json.Unmarshal(body, &m); err != nil {
		return m, errors.Wrap(err, "could not unmarshal body")
	}

	return m, nil
}

// GetTorrentUploadLimit get upload speed limit for torrents specified by hashes.
//
// example response:
//
//	{
//		"8c212779b4abde7c6bc608063a0d008b7e40ce32":338944,
//		"284b83c9c7935002391129fd97f43db5d7cc2ba0":123
//	}
//
// 8c212779b4abde7c6bc608063a0d008b7e40ce32 is the hash of the torrent and
// 338944 its upload speed limit in bytes per second;
// this value will be zero if no limit is applied.
func (c *Client) GetTorrentUploadLimit(hashes []string) (map[string]int64, error) {
	return c.GetTorrentUploadLimitCtx(context.Background(), hashes)
}

// GetTorrentUploadLimitCtx get upload speed limit for torrents specified by hashes.
//
// example response:
//
//	{
//		"8c212779b4abde7c6bc608063a0d008b7e40ce32":338944,
//		"284b83c9c7935002391129fd97f43db5d7cc2ba0":123
//	}
//
// 8c212779b4abde7c6bc608063a0d008b7e40ce32 is the hash of the torrent and
// 338944 its upload speed limit in bytes per second;
// this value will be zero if no limit is applied.
func (c *Client) GetTorrentUploadLimitCtx(ctx context.Context, hashes []string) (map[string]int64, error) {
	opts := map[string]string{
		"hashes": strings.Join(hashes, "|"),
	}

	resp, err := c.postCtx(ctx, "torrents/uploadLimit", opts)
	if err != nil {
		return nil, errors.Wrap(err, "could not get upload speed limit; hashes: %v", hashes)
	}

	defer func(Body io.ReadCloser) {
		_ = Body.Close()
	}(resp.Body)

	if resp.StatusCode != http.StatusOK {
		return nil, errors.Wrap(ErrUnexpectedStatus, "could not get upload speed limit; hashes: %v | status code: %d", hashes, resp.StatusCode)
	}

	ret := make(map[string]int64)
	if err = json.NewDecoder(resp.Body).Decode(&ret); err != nil {
		return nil, errors.Wrap(err, "could not decode response body")
	}

	return ret, nil
}

// GetTorrentDownloadLimit get download limit for torrents specified by hashes.
//
// example response:
//
//	{
//		"8c212779b4abde7c6bc608063a0d008b7e40ce32":338944,
//		"284b83c9c7935002391129fd97f43db5d7cc2ba0":123
//	}
//
// 8c212779b4abde7c6bc608063a0d008b7e40ce32 is the hash of the torrent and
// 338944 its download speed limit in bytes per second;
// this value will be zero if no limit is applied.
func (c *Client) GetTorrentDownloadLimit(hashes []string) (map[string]int64, error) {
	return c.GetTorrentDownloadLimitCtx(context.Background(), hashes)
}

// GetTorrentDownloadLimitCtx get download limit for torrents specified by hashes.
//
// example response:
//
//	{
//		"8c212779b4abde7c6bc608063a0d008b7e40ce32":338944,
//		"284b83c9c7935002391129fd97f43db5d7cc2ba0":123
//	}
//
// 8c212779b4abde7c6bc608063a0d008b7e40ce32 is the hash of the torrent and
// 338944 its download speed limit in bytes per second;
// this value will be zero if no limit is applied.
func (c *Client) GetTorrentDownloadLimitCtx(ctx context.Context, hashes []string) (map[string]int64, error) {
	opts := map[string]string{
		"hashes": strings.Join(hashes, "|"),
	}

	resp, err := c.postCtx(ctx, "torrents/downloadLimit", opts)
	if err != nil {
		return nil, errors.Wrap(err, "could not get download limit; hashes: %v", hashes)
	}

	defer func(Body io.ReadCloser) {
		_ = Body.Close()
	}(resp.Body)

	if resp.StatusCode != http.StatusOK {
		return nil, errors.Wrap(ErrUnexpectedStatus, "could not get download limit; hashes: %v | status code: %d", hashes, resp.StatusCode)
	}

	ret := make(map[string]int64)
	if err = json.NewDecoder(resp.Body).Decode(&ret); err != nil {
		return nil, errors.Wrap(err, "could not decode response body")
	}

	return ret, nil
}

// SetTorrentDownloadLimit set download limit for torrents specified by hashes
func (c *Client) SetTorrentDownloadLimit(hashes []string, limit int64) error {
	return c.SetTorrentDownloadLimitCtx(context.Background(), hashes, limit)
}

// SetTorrentDownloadLimitCtx set download limit for torrents specified by hashes
func (c *Client) SetTorrentDownloadLimitCtx(ctx context.Context, hashes []string, limit int64) error {
	opts := map[string]string{
		"hashes": strings.Join(hashes, "|"),
		"limit":  strconv.FormatInt(limit, 10),
	}

	resp, err := c.postCtx(ctx, "torrents/setDownloadLimit", opts)
	if err != nil {
		return errors.Wrap(err, "could not set download limit; hashes: %v", hashes)
	}

	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not set download limit; hashes: %v | status code: %d", hashes, resp.StatusCode)
	}

	return nil
}

// ToggleTorrentSequentialDownload toggles sequential download mode for torrents specified by hashes.
//
// hashes contains the hashes of the torrents to toggle sequential download mode for.
// or you can set to "all" to toggle sequential download mode for all torrents.
func (c *Client) ToggleTorrentSequentialDownload(hashes []string) error {
	return c.ToggleTorrentSequentialDownloadCtx(context.Background(), hashes)
}

// ToggleTorrentSequentialDownloadCtx toggles sequential download mode for torrents specified by hashes.
//
// hashes contains the hashes of the torrents to toggle sequential download mode for.
// or you can set to "all" to toggle sequential download mode for all torrents.
func (c *Client) ToggleTorrentSequentialDownloadCtx(ctx context.Context, hashes []string) error {
	opts := map[string]string{
		"hashes": strings.Join(hashes, "|"),
	}

	resp, err := c.postCtx(ctx, "torrents/toggleSequentialDownload", opts)
	if err != nil {
		return errors.Wrap(err, "could not toggle sequential download mode; hashes: %v", hashes)
	}

	defer func(Body io.ReadCloser) {
		_ = Body.Close()
	}(resp.Body)

	if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not toggle sequential download mode; hashes: %v | status code: %d", hashes, resp.StatusCode)
	}

	return nil
}

// SetTorrentSuperSeeding set super speeding mode for torrents specified by hashes.
//
// hashes contains the hashes of the torrents to set super seeding mode for.
// or you can set to "all" to set super seeding mode for all torrents.
func (c *Client) SetTorrentSuperSeeding(hashes []string, on bool) error {
	return c.SetTorrentSuperSeedingCtx(context.Background(), hashes, on)
}

// SetTorrentSuperSeedingCtx set super seeding mode for torrents specified by hashes.
//
// hashes contains the hashes of the torrents to set super seeding mode for.
// or you can set to "all" to set super seeding mode for all torrents.
func (c *Client) SetTorrentSuperSeedingCtx(ctx context.Context, hashes []string, on bool) error {
	value := "false"
	if on {
		value = "true"
	}
	opts := map[string]string{
		"hashes": strings.Join(hashes, "|"),
		"value":  value,
	}

	resp, err := c.postCtx(ctx, "torrents/setSuperSeeding", opts)
	if err != nil {
		return errors.Wrap(err, "could not set super seeding mode; hashes: %v", hashes)
	}

	defer func(Body io.ReadCloser) {
		_ = Body.Close()
	}(resp.Body)

	if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not set super seeding mode; hashes: %v | status code: %d", hashes, resp.StatusCode)
	}

	return nil
}

// SetTorrentShareLimit set share limits for torrents specified by hashes
func (c *Client) SetTorrentShareLimit(hashes []string, ratioLimit float64, seedingTimeLimit int64, inactiveSeedingTimeLimit int64) error {
	return c.SetTorrentShareLimitCtx(context.Background(), hashes, ratioLimit, seedingTimeLimit, inactiveSeedingTimeLimit)
}

// SetTorrentShareLimitCtx set share limits for torrents specified by hashes
func (c *Client) SetTorrentShareLimitCtx(ctx context.Context, hashes []string, ratioLimit float64, seedingTimeLimit int64, inactiveSeedingTimeLimit int64) error {
	opts := map[string]string{
		"hashes":                   strings.Join(hashes, "|"),
		"ratioLimit":               strconv.FormatFloat(ratioLimit, 'f', 2, 64),
		"seedingTimeLimit":         strconv.FormatInt(seedingTimeLimit, 10),
		"inactiveSeedingTimeLimit": strconv.FormatInt(inactiveSeedingTimeLimit, 10),
	}

	resp, err := c.postCtx(ctx, "torrents/setShareLimits", opts)
	if err != nil {
		return errors.Wrap(err, "could not set share limits; hashes: %v | ratioLimit: %v | seedingTimeLimit: %v | inactiveSeedingTimeLimit %v", hashes, ratioLimit, seedingTimeLimit, inactiveSeedingTimeLimit)
	}

	defer resp.Body.Close()

	/*
		HTTP Status Code 	Scenario
		400 	Share limit or at least one id is invalid
		200 	All other scenarios
	*/
	switch sc := resp.StatusCode; sc {
	case http.StatusOK:
		return nil
	case http.StatusBadRequest:
		return ErrInvalidShareLimit
	default:
		errors.Wrap(ErrUnexpectedStatus, "could not set share limits; hashes: %v | ratioLimit: %v | seedingTimeLimit: %v | inactiveSeedingTimeLimit %v | status code: %d", hashes, ratioLimit, seedingTimeLimit, inactiveSeedingTimeLimit, resp.StatusCode)
	}

	return nil
}

// SetTorrentUploadLimit set upload limit for torrent specified by hashes
func (c *Client) SetTorrentUploadLimit(hashes []string, limit int64) error {
	return c.SetTorrentUploadLimitCtx(context.Background(), hashes, limit)
}

// SetTorrentUploadLimitCtx set upload limit for torrent specified by hashes
func (c *Client) SetTorrentUploadLimitCtx(ctx context.Context, hashes []string, limit int64) error {
	opts := map[string]string{
		"hashes": strings.Join(hashes, "|"),
		"limit":  strconv.FormatInt(limit, 10),
	}

	resp, err := c.postCtx(ctx, "torrents/setUploadLimit", opts)
	if err != nil {
		return errors.Wrap(err, "could not set upload limit; hashes: %v", hashes)
	}

	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return errors.Wrap(ErrUnexpectedStatus, "could not set upload limit; hahses: %v | status code: %d", hashes, resp.StatusCode)
	}

	return nil
}

func (c *Client) GetAppVersion() (string, error) {
	return c.GetAppVersionCtx(context.Background())
}

func (c *Client) GetAppVersionCtx(ctx context.Context) (string, error) {
	resp, err := c.getCtx(ctx, "app/version", nil)
	if err != nil {
		return "", errors.Wrap(err, "could not get app version")
	}

	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return "", errors.Wrap(err, "could not read body")
	}

	return string(body), nil
}

// GetAppCookies get app cookies.
// Cookies are used for downloading torrents.
func (c *Client) GetAppCookies() ([]Cookie, error) {
	return c.GetAppCookiesCtx(context.Background())
}

// GetAppCookiesCtx get app cookies.
// Cookies are used for downloading torrents.
func (c *Client) GetAppCookiesCtx(ctx context.Context) ([]Cookie, error) {
	resp, err := c.getCtx(ctx, "app/cookies", nil)
	if err != nil {
		return nil, errors.Wrap(err, "could not get app cookies")
	}

	defer func(Body io.ReadCloser) {
		_ = Body.Close()
	}(resp.Body)

	if resp.StatusCode != http.StatusOK {
		return nil, errors.Wrap(ErrUnexpectedStatus, "could not get app cookies; status code: %d", resp.StatusCode)
	}

	var cookies []Cookie
	if err = json.NewDecoder(resp.Body).Decode(&cookies); err != nil {
		return nil, errors.Wrap(err, "could not decode response body")
	}

	return cookies, nil
}

// SetAppCookies get app cookies.
// Cookies are used for downloading torrents.
func (c *Client) SetAppCookies(cookies []Cookie) error {
	return c.SetAppCookiesCtx(context.Background(), cookies)
}

// SetAppCookiesCtx get app cookies.
// Cookies are used for downloading torrents.
func (c *Client) SetAppCookiesCtx(ctx context.Context, cookies []Cookie) error {
	marshaled, err := json.Marshal(cookies)
	if err != nil {
		return errors.Wrap(err, "could not marshal cookies")
	}

	opts := map[string]string{
		"cookies": string(marshaled),
	}
	resp, err := c.postCtx(ctx, "app/setCookies", opts)
	if err != nil {
		return errors.Wrap(err, "could not set app cookies")
	}

	defer func(Body io.ReadCloser) {
		_ = Body.Close()
	}(resp.Body)

	switch resp.StatusCode {
	case http.StatusBadRequest:
		data, _ := io.ReadAll(resp.Body)
		_ = data
		return ErrInvalidCookies
	case http.StatusOK:
		return nil
	default:
		return errors.Wrap(ErrUnexpectedStatus, "could not set app cookies; status code: %d", resp.StatusCode)
	}
}

// GetTorrentPieceStates returns an array of states (integers) of all pieces (in order) of a specific torrent.
func (c *Client) GetTorrentPieceStates(hash string) ([]PieceState, error) {
	return c.GetTorrentPieceStatesCtx(context.Background(), hash)
}

// GetTorrentPieceStatesCtx returns an array of states (integers) of all pieces (in order) of a specific torrent.
func (c *Client) GetTorrentPieceStatesCtx(ctx context.Context, hash string) ([]PieceState, error) {
	opts := map[string]string{
		"hash": hash,
	}
	resp, err := c.getCtx(ctx, "torrents/pieceStates", opts)
	if err != nil {
		return nil, errors.Wrap(err, "could not get torrent piece states")
	}

	defer func(Body io.ReadCloser) {
		_ = Body.Close()
	}(resp.Body)

	if resp.StatusCode != http.StatusOK {
		return nil, errors.Wrap(ErrCannotGetTorrentPieceStates, "torrent hash %v, unexpected status: %v", hash, resp.StatusCode)
	}

	var result []PieceState
	if err = json.NewDecoder(resp.Body).Decode(&result); err != nil {
		return nil, errors.Wrap(err, "could not decode response body")
	}

	return result, nil
}

// GetTorrentPieceHashes returns an array of hashes (in order) of all pieces (in order) of a specific torrent.
func (c *Client) GetTorrentPieceHashes(hash string) ([]string, error) {
	return c.GetTorrentPieceHashesCtx(context.Background(), hash)
}

// GetTorrentPieceHashesCtx returns an array of hashes (in order) of all pieces (in order) of a specific torrent.
func (c *Client) GetTorrentPieceHashesCtx(ctx context.Context, hash string) ([]string, error) {
	opts := map[string]string{
		"hash": hash,
	}
	resp, err := c.getCtx(ctx, "torrents/pieceHashes", opts)
	if err != nil {
		return nil, errors.Wrap(err, "could not get torrent piece hashes: hashes %v", hash)
	}

	defer func(Body io.ReadCloser) {
		_ = Body.Close()
	}(resp.Body)

	switch resp.StatusCode {
	case http.StatusNotFound:
		return nil, errors.Wrap(ErrTorrentNotFound, "torrent hash %v", hash)
	case http.StatusOK:
		break
	default:
		return nil, errors.Wrap(ErrUnexpectedStatus, "could not get torrent piece hashes; hash: %v, status code: %d", hash, resp.StatusCode)
	}

	var result []string
	if err = json.NewDecoder(resp.Body).Decode(&result); err != nil {
		return nil, errors.Wrap(err, "could not decode response body")
	}

	return result, nil
}

// AddPeersForTorrents adds peers to torrents.
// hashes is a list of torrent hashes.
// peers is a list of peers. Each of peers list is a string in the form of `<ip>:<port>`.
func (c *Client) AddPeersForTorrents(hashes, peers []string) error {
	return c.AddPeersForTorrentsCtx(context.Background(), hashes, peers)
}

// AddPeersForTorrentsCtx adds peers to torrents.
// hashes is a list of torrent hashes.
// peers is a list of peers. Each of peers list is a string in the form of `<ip>:<port>`.
func (c *Client) AddPeersForTorrentsCtx(ctx context.Context, hashes, peers []string) error {
	opts := map[string]string{
		"hashes": strings.Join(hashes, "|"),
		"peers":  strings.Join(peers, "|"),
	}
	resp, err := c.postCtx(ctx, "torrents/addPeers", opts)
	if err != nil {
		return errors.Wrap(err, "could not add peers; hashes: %v | peers: %v", hashes, peers)
	}

	defer func(Body io.ReadCloser) {
		_ = Body.Close()
	}(resp.Body)

	switch resp.StatusCode {
	case http.StatusBadRequest:
		return errors.Wrap(ErrInvalidPeers, "hashes: %v, peers: %v", hashes, peers)
	case http.StatusOK:
		return nil
	default:
		return errors.Wrap(ErrUnexpectedStatus, "could not add peers; hashes %v | peers: %v | status code: %d", hashes, peers, resp.StatusCode)
	}
}

func (c *Client) GetWebAPIVersion() (string, error) {
	return c.GetWebAPIVersionCtx(context.Background())
}

func (c *Client) GetWebAPIVersionCtx(ctx context.Context) (string, error) {
	resp, err := c.getCtx(ctx, "app/webapiVersion", nil)
	if err != nil {
		return "", errors.Wrap(err, "could not get webapi version")
	}

	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return "", errors.Wrap(err, "could not read body")
	}

	return string(body), nil
}

// GetLogs get main client logs
func (c *Client) GetLogs() ([]Log, error) {
	return c.GetLogsCtx(context.Background())
}

// GetLogsCtx get main client logs
func (c *Client) GetLogsCtx(ctx context.Context) ([]Log, error) {
	resp, err := c.getCtx(ctx, "log/main", nil)
	if err != nil {
		return nil, errors.Wrap(err, "could not get main client logs")
	}

	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, errors.Wrap(err, "could not read body")
	}

	m := make([]Log, 0)
	if err := json.Unmarshal(body, &m); err != nil {
		return nil, errors.Wrap(err, "could not unmarshal body")
	}

	return m, nil
}

// GetPeerLogs get peer logs
func (c *Client) GetPeerLogs() ([]PeerLog, error) {
	return c.GetPeerLogsCtx(context.Background())
}

// GetPeerLogsCtx get peer logs
func (c *Client) GetPeerLogsCtx(ctx context.Context) ([]PeerLog, error) {
	resp, err := c.getCtx(ctx, "log/main", nil)
	if err != nil {
		return nil, errors.Wrap(err, "could not get peer logs")
	}

	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return nil, errors.Wrap(err, "could not read body")
	}

	m := make([]PeerLog, 0)
	if err := json.Unmarshal(body, &m); err != nil {
		return nil, errors.Wrap(err, "could not unmarshal body")
	}

	return m, nil
}

func (c *Client) GetFreeSpaceOnDisk() (int64, error) {
	return c.GetFreeSpaceOnDiskCtx(context.Background())
}

// GetFreeSpaceOnDiskCtx get free space on disk for default download dir. Expensive call
func (c *Client) GetFreeSpaceOnDiskCtx(ctx context.Context) (int64, error) {
	info, err := c.SyncMainDataCtx(ctx, 0)
	if err != nil {
		return 0, errors.Wrap(err, "could not get maindata")
	}

	return info.ServerState.FreeSpaceOnDisk, nil
}

// RequiresMinVersion checks the current version against version X and errors if the current version is older than X
func (c *Client) RequiresMinVersion(minVersion *semver.Version) (bool, error) {
	version, err := c.getApiVersion()
	if err != nil {
		return false, errors.Wrap(err, "could not get api version")
	}

	if version.LessThan(minVersion) {
		return false, errors.Wrap(ErrUnsupportedVersion, "qBittorrent WebAPI version %s is older than required %s", version.String(), minVersion.String())
	}

	return true, nil
}

const (
	ReannounceMaxAttempts = 50
	ReannounceInterval    = 7 // interval in seconds
)

type ReannounceOptions struct {
	Interval        int
	MaxAttempts     int
	DeleteOnFailure bool
}

func (c *Client) ReannounceTorrentWithRetry(ctx context.Context, hash string, opts *ReannounceOptions) error {
	interval := ReannounceInterval
	maxAttempts := ReannounceMaxAttempts
	deleteOnFailure := false

	if opts != nil {
		if opts.Interval > 0 {
			interval = opts.Interval
		}

		if opts.MaxAttempts > 0 {
			maxAttempts = opts.MaxAttempts
		}

		if opts.DeleteOnFailure {
			deleteOnFailure = opts.DeleteOnFailure
		}
	}

	attempts := 0

	for attempts < maxAttempts {
		c.log.Printf("re-announce %s attempt: %d", hash, attempts)

		// add delay for next run
		time.Sleep(time.Duration(interval) * time.Second)

		trackers, err := c.GetTorrentTrackersCtx(ctx, hash)
		if err != nil {
			return errors.Wrap(err, "could not get trackers for torrent with hash: %s", hash)
		}

		if trackers == nil {
			attempts++
			continue
		}

		c.log.Printf("re-announce %s attempt: %d trackers (%+v)", hash, attempts, trackers)

		// check if status not working or something else
		if isTrackerStatusOK(trackers) {
			c.log.Printf("re-announce for %v OK", hash)

			// if working lets return
			return nil
		}

		c.log.Printf("not working yet, lets re-announce %s attempt: %d", hash, attempts)

		if err = c.ReAnnounceTorrentsCtx(ctx, []string{hash}); err != nil {
			return errors.Wrap(err, "could not re-announce torrent with hash: %s", hash)
		}

		attempts++
	}

	// delete on failure to reannounce
	if deleteOnFailure {
		c.log.Printf("re-announce for %s took too long, deleting torrent", hash)

		if err := c.DeleteTorrentsCtx(ctx, []string{hash}, false); err != nil {
			return errors.Wrap(err, "could not delete torrent with hash: %s", hash)
		}

		return ErrReannounceTookTooLong
	}

	return nil
}

func (c *Client) GetTorrentsWebSeeds(hash string) ([]WebSeed, error) {
	return c.GetTorrentsWebSeedsCtx(context.Background(), hash)
}

func (c *Client) GetTorrentsWebSeedsCtx(ctx context.Context, hash string) ([]WebSeed, error) {
	opts := map[string]string{
		"hash": hash,
	}
	resp, err := c.getCtx(ctx, "torrents/webseeds", opts)
	if err != nil {
		return nil, errors.Wrap(err, "could not get webseeds for torrent; hash: %s", hash)
	}
	defer func(Body io.ReadCloser) {
		_ = Body.Close()
	}(resp.Body)

	switch resp.StatusCode {
	case http.StatusNotFound:
		return nil, errors.Wrap(ErrTorrentNotFound, "hash: %s", hash)
	case http.StatusOK:
		break
	default:
		return nil, errors.Wrap(ErrUnexpectedStatus, "could not get webseeds for torrent; hash: %v, status code: %d", hash, resp.StatusCode)
	}

	var m []WebSeed
	if err = json.NewDecoder(resp.Body).Decode(&m); err != nil {
		return nil, errors.Wrap(err, "could not decode response")
	}

	return m, nil
}

// Check if status not working or something else
// https://github.com/qbittorrent/qBittorrent/wiki/WebUI-API-(qBittorrent-4.1)#get-torrent-trackers
//
//	0 Tracker is disabled (used for DHT, PeX, and LSD)
//	1 Tracker has not been contacted yet
//	2 Tracker has been contacted and is working
//	3 Tracker is updating
//	4 Tracker has been contacted, but it is not working (or doesn't send proper replies)
func isTrackerStatusOK(trackers []TorrentTracker) bool {
	for _, tracker := range trackers {
		if tracker.Status == TrackerStatusDisabled {
			continue
		}

		// check for certain messages before the tracker status to catch ok status with unreg msg
		if isUnregistered(tracker.Message) {
			return false
		}

		if tracker.Status == TrackerStatusOK {
			return true
		}
	}

	return false
}

func isUnregistered(msg string) bool {
	words := []string{"unregistered", "not registered", "not found", "not exist"}

	msg = strings.ToLower(msg)

	for _, v := range words {
		if strings.Contains(msg, v) {
			return true
		}
	}

	return false
}
</file>

</files>
